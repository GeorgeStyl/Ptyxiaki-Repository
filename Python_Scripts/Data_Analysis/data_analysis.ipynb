{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/georger/WorkDocuments/Sxoli/Ptyxiaki/Ptyxiaki-Repository/Python_Scripts/Data_Analysis\n",
      "['Powerfleet_API_Management.py', 'JSON_response.json', '__pycache__', 'data_analysis.ipynb', 'response_data_set.csv', 'Powerfleet_API_CredentialsI.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from colorama import Fore, Back, Style\n",
    "\n",
    "print(f\"{os.getcwd()}\")\n",
    "print(f\"{os.listdir()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert **JSON** to **CSV** so that **pandas** be able to use it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os.getcwd()='/home/georger/WorkDocuments/Sxoli/Ptyxiaki/Ptyxiaki-Repository/Python_Scripts/Data_Analysis'\n",
      "['Powerfleet_API_Management.py', 'JSON_response.json', '__pycache__', 'data_analysis.ipynb', 'response_data_set.csv', 'Powerfleet_API_CredentialsI.txt']\n",
      "Headers: {'Content-Type': 'application/json', 'Authorization': '00595c0d-01d4-38a3-ba06-8852a0c6b2b8'}\n",
      "Data: {'startDate': '2023-10-23 15:32:24', 'endDate': '2024-11-25 15:32:24', 'vehicleId': 7, 'cid': '946'}\n",
      "\u001b[32mSuccess: 200\n",
      "\u001b[0m\n",
      "\u001b[32mCSV file saved as response_data_set.csv\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from Powerfleet_API_Management import PowerfleetAPIManager as powerfleet_API\n",
    "from colorama import Fore, Style\n",
    "\n",
    "startDate = \"2023-10-23 15:32:24\"  # Indicative start date\n",
    "endDate = \"2024-11-25 15:32:24\"  # Indicative end date\n",
    "api_manager = powerfleet_API(startDate, endDate)  # Get data\n",
    "\n",
    "output_file = \"response_data_set.csv\"\n",
    "\n",
    "# Retrieve response data from the API\n",
    "response_data = api_manager.retrieve_response()\n",
    "\n",
    "# Write the JSON response data to a file\n",
    "with open('JSON_response.json', 'w') as json_file:\n",
    "    json.dump(response_data, json_file, indent=4)\n",
    "\n",
    "try:\n",
    "    # Read the JSON file into a pandas DataFrame\n",
    "    df = pd.read_json('JSON_response.json')\n",
    "\n",
    "    # Add the start and end date columns to the DataFrame\n",
    "    df['startDate'] = startDate\n",
    "    df['endDate'] = endDate\n",
    "\n",
    "    # Write the DataFrame to CSV\n",
    "    df.to_csv(output_file, index=False)\n",
    "\n",
    "    print(Fore.GREEN + f\"CSV file saved as {output_file}\")\n",
    "    print(Style.RESET_ALL)\n",
    "\n",
    "except ValueError as e:\n",
    "    print(Fore.RED + \"Error: The JSON file structure is not appropriate for conversion.\", e)\n",
    "    print(Style.RESET_ALL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if csv1 and csv2 are duplicates. Dont use columns: startDate,endDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CSV files are duplicates (ignoring 'startDate' and 'endDate').\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV files into pandas DataFrames\n",
    "df1 = pd.read_csv('response_data_set.csv')\n",
    "df2 = pd.read_csv('response_data_set2.csv')\n",
    "\n",
    "# Drop the 'startDate' and 'endDate' columns from both DataFrames\n",
    "df1_cleaned = df1.drop(columns=['startDate', 'endDate'], errors='ignore')\n",
    "df2_cleaned = df2.drop(columns=['startDate', 'endDate'], errors='ignore')\n",
    "\n",
    "# Check if the two DataFrames are the same\n",
    "if df1_cleaned.equals(df2_cleaned):\n",
    "    print(\"The CSV files are duplicates (ignoring 'startDate' and 'endDate').\")\n",
    "else:\n",
    "    print(\"The CSV files are not duplicates.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGIS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
