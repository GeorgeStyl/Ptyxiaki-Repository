{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:02.444705Z",
     "start_time": "2025-02-01T18:48:02.442519Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.neighbors import KernelDensity, BallTree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial import ConvexHull\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import os\n",
    "from colorama import Fore, Style\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import ConvexHull\n",
    "from shapely.geometry import Polygon\n",
    "import json\n",
    "import plotly.express as px\n",
    "from haversine import haversine, Unit\n",
    "import math\n",
    "import random\n",
    "import seaborn as sns\n",
    "from scipy.stats import circstd, circmean\n",
    "from scipy.stats import gaussian_kde\n",
    "import statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# File loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:02.670714Z",
     "start_time": "2025-02-01T18:48:02.667030Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"vehicleId\", \n",
    "    \"lat\", \n",
    "    \"lng\", \n",
    "    # \"dateStored\", \n",
    "    \"velocity\",\n",
    "    # \"odometer\", \n",
    "    # \"engineVoltage\", \n",
    "    \"dateStoredHuman\", \n",
    "    # \"dateOnlyStoredHuman\",    \n",
    "    # \"timeOnly\",\n",
    "    \"bearing\",\n",
    "    \"orientation\", \n",
    "    \"bearing_diff\",\n",
    "    \"seconds_diff\", \n",
    "    \"acceleration\",\n",
    "    \"isProblem\",\n",
    "    \"trip_id\",\n",
    "    \"velocity_diff\",\n",
    "    \"distance_m\"\n",
    "]\n",
    "\n",
    "\n",
    "input_dir   = \"../../DataSets/API_Responses/Vehicle_Data/\"\n",
    "filename    = \"all_vehicle_responses.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable matloblib UI backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save plots file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_FOLDER_PATH = \"./Plots/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:03.383127Z",
     "start_time": "2025-02-01T18:48:03.325978Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   vehicleId        lat        lng  velocity      dateStoredHuman  \\\n",
      "0          1  37.510833  22.385710       0.0  2024-06-06 17:02:17   \n",
      "1          1  37.510603  22.385977       0.0  2024-06-06 17:02:20   \n",
      "2          1  37.510640  22.385927       6.0  2024-06-06 17:02:25   \n",
      "3          1  37.510750  22.385907       7.0  2024-06-06 17:02:31   \n",
      "4          1  37.510877  22.385698      26.0  2024-06-06 17:02:37   \n",
      "\n",
      "   seconds_diff  trip_id  distance_m     bearing orientation  bearing_diff  \\\n",
      "0           0.0        0        0.00  137.402376   Southeast          0.00   \n",
      "1           3.0        0       34.75  312.778670   Northwest        175.38   \n",
      "2           5.0        0        6.01  351.785725       North         39.01   \n",
      "3           6.0        0       12.33  307.481149   Northwest         44.30   \n",
      "4           6.0        0       23.17  318.388767   Northwest         10.91   \n",
      "\n",
      "   velocity_diff  acceleration  isProblem  \n",
      "0            0.0      0.000000          0  \n",
      "1            0.0      0.000000          0  \n",
      "2            6.0      0.333333          0  \n",
      "3            1.0      0.046296          0  \n",
      "4           19.0      0.879630          0  \n"
     ]
    }
   ],
   "source": [
    "def merge_csv_file(input_dir, filename, columns):\n",
    "    input_file = os.path.join(input_dir, filename)\n",
    "\n",
    "    if not os.path.exists(input_file):\n",
    "        raise FileNotFoundError(f\"File '{filename}' not found in directory '{input_dir}'\")\n",
    "\n",
    "    try:\n",
    "        # Read the CSV while allowing missing columns\n",
    "        df = pd.read_csv(input_file, usecols=lambda x: x.strip() in columns, encoding='utf-8')\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error reading '{input_file}': {e}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "merged_dfs = merge_csv_file(input_dir, filename, columns)\n",
    "print(merged_dfs.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set **Bounding Box** only for **Τρίπολη**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:12.258811Z",
     "start_time": "2025-02-01T18:48:12.187714Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Density of problem points on spatial coordinates')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = merged_dfs\n",
    "# df_danger = df[df['isProblem'] == 1]\n",
    "df_danger = df[df['vehicleId'] == 15]\n",
    "\n",
    "\n",
    "sns.set_theme(style=\"ticks\")\n",
    "fig, ax = plt.subplots()\n",
    "#sns.jointplot(x=df_danger['lng'], y=df_danger['lat'], kind=\"hex\", color=\"#4CB391\", ax=ax)\n",
    "ax.hexbin(x=df_danger['lng'], y=df_danger['lat'])\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "\n",
    "plt.gca().xaxis.set_major_formatter(ScalarFormatter())\n",
    "plt.gca().yaxis.set_major_formatter(ScalarFormatter())\n",
    "plt.ticklabel_format(style='plain', axis='both')  # Disable scientific notation\n",
    "\n",
    "\n",
    "ax.set_title('Density of problem points on spatial coordinates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:12.613965Z",
     "start_time": "2025-02-01T18:48:12.598846Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_danger[['lng', 'lat']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:17.330420Z",
     "start_time": "2025-02-01T18:48:17.325963Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #### MOCK DATA #####\n",
    "#\n",
    "# data = {\n",
    "#     'lng': np.random.uniform(-180, 180, 200),\n",
    "#     'lat': np.random.uniform(-90, 90, 200)\n",
    "# }\n",
    "# df = pd.DataFrame(data)\n",
    "# df_danger = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:17.808617Z",
     "start_time": "2025-02-01T18:48:17.802262Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:18.846543Z",
     "start_time": "2025-02-01T18:48:18.474283Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16608/2364819354.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_danger.loc[:, 'cluster'] = clusters  # Adding cluster labels to DataFrame\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to ./Plots/\n"
     ]
    }
   ],
   "source": [
    "# Extracting the coordinates\n",
    "coords = df_danger[['lng', 'lat']].values\n",
    "\n",
    "# Standardizing the data for better clustering performance\n",
    "scaler = StandardScaler()\n",
    "coords_scaled = scaler.fit_transform(coords)\n",
    "\n",
    "# Applying DBSCAN\n",
    "dbscan = DBSCAN(eps=0.02, min_samples=4)  # Adjust eps as needed\n",
    "clusters = dbscan.fit_predict(coords_scaled)\n",
    "\n",
    "df_danger.loc[:, 'cluster'] = clusters  # Adding cluster labels to DataFrame\n",
    "\n",
    "\n",
    "df_danger_cluster = df_danger[df_danger['cluster'] > -1]\n",
    "\n",
    "\n",
    "# %matplotlib inline\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df_danger_cluster['lng'], df_danger_cluster['lat'], c=df_danger_cluster['cluster'], cmap='tab10', edgecolors='k', alpha=0.7)\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('DBSCAN Clustering of Geospatial Data')\n",
    "plt.colorbar(label='Cluster')\n",
    "\n",
    "# Save the plot\n",
    "# Define the path to save the plot\n",
    "plot_save_path = os.path.join(PLOT_FOLDER_PATH, \"DBSCAN_Clustering_of_Geospatial_Data.png\")\n",
    "plt.savefig(plot_save_path, bbox_inches='tight')\n",
    "print(f\"Plot saved to {PLOT_FOLDER_PATH}\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:18.984524Z",
     "start_time": "2025-02-01T18:48:18.979522Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['vehicleId', 'lat', 'lng', 'velocity', 'dateStoredHuman',\n",
       "       'seconds_diff', 'trip_id', 'distance_m', 'bearing', 'orientation',\n",
       "       'bearing_diff', 'velocity_diff', 'acceleration', 'isProblem',\n",
       "       'cluster'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_danger.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vehicleId</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>velocity</th>\n",
       "      <th>seconds_diff</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>distance_m</th>\n",
       "      <th>bearing</th>\n",
       "      <th>bearing_diff</th>\n",
       "      <th>velocity_diff</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>isProblem</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1517.0</td>\n",
       "      <td>1517.000000</td>\n",
       "      <td>1517.000000</td>\n",
       "      <td>1517.000000</td>\n",
       "      <td>1517.000000</td>\n",
       "      <td>1517.000000</td>\n",
       "      <td>1517.000000</td>\n",
       "      <td>1517.000000</td>\n",
       "      <td>1517.000000</td>\n",
       "      <td>1517.000000</td>\n",
       "      <td>1517.000000</td>\n",
       "      <td>1517.000000</td>\n",
       "      <td>1517.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15.0</td>\n",
       "      <td>37.514896</td>\n",
       "      <td>22.382625</td>\n",
       "      <td>19.600527</td>\n",
       "      <td>4.143705</td>\n",
       "      <td>139.842452</td>\n",
       "      <td>12.565485</td>\n",
       "      <td>205.088664</td>\n",
       "      <td>83.951365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014870</td>\n",
       "      <td>0.127884</td>\n",
       "      <td>1.253131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006654</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>12.671096</td>\n",
       "      <td>5.510165</td>\n",
       "      <td>69.293158</td>\n",
       "      <td>21.848633</td>\n",
       "      <td>108.365935</td>\n",
       "      <td>101.405398</td>\n",
       "      <td>8.033324</td>\n",
       "      <td>0.671664</td>\n",
       "      <td>0.334071</td>\n",
       "      <td>4.543167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15.0</td>\n",
       "      <td>37.506782</td>\n",
       "      <td>22.360795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-39.000000</td>\n",
       "      <td>-4.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15.0</td>\n",
       "      <td>37.510752</td>\n",
       "      <td>22.380318</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>4.510000</td>\n",
       "      <td>104.289875</td>\n",
       "      <td>5.770000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-0.277778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15.0</td>\n",
       "      <td>37.510957</td>\n",
       "      <td>22.385692</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>9.220000</td>\n",
       "      <td>246.743638</td>\n",
       "      <td>27.530000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.0</td>\n",
       "      <td>37.520865</td>\n",
       "      <td>22.386168</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>16.770000</td>\n",
       "      <td>291.443161</td>\n",
       "      <td>155.770000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.0</td>\n",
       "      <td>37.532238</td>\n",
       "      <td>22.387758</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>552.080000</td>\n",
       "      <td>359.286728</td>\n",
       "      <td>356.350000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       vehicleId          lat          lng     velocity  seconds_diff  \\\n",
       "count     1517.0  1517.000000  1517.000000  1517.000000   1517.000000   \n",
       "mean        15.0    37.514896    22.382625    19.600527      4.143705   \n",
       "std          0.0     0.006654     0.005373    12.671096      5.510165   \n",
       "min         15.0    37.506782    22.360795     0.000000      0.000000   \n",
       "25%         15.0    37.510752    22.380318    10.000000      1.000000   \n",
       "50%         15.0    37.510957    22.385692    18.000000      2.000000   \n",
       "75%         15.0    37.520865    22.386168    28.000000      5.000000   \n",
       "max         15.0    37.532238    22.387758    55.000000     46.000000   \n",
       "\n",
       "           trip_id   distance_m      bearing  bearing_diff  velocity_diff  \\\n",
       "count  1517.000000  1517.000000  1517.000000   1517.000000    1517.000000   \n",
       "mean    139.842452    12.565485   205.088664     83.951365       0.000000   \n",
       "std      69.293158    21.848633   108.365935    101.405398       8.033324   \n",
       "min       1.000000     0.000000     0.000000      0.000000     -39.000000   \n",
       "25%      79.000000     4.510000   104.289875      5.770000      -4.000000   \n",
       "50%     160.000000     9.220000   246.743638     27.530000       0.000000   \n",
       "75%     207.000000    16.770000   291.443161    155.770000       3.000000   \n",
       "max     208.000000   552.080000   359.286728    356.350000      39.000000   \n",
       "\n",
       "       acceleration    isProblem      cluster  \n",
       "count   1517.000000  1517.000000  1517.000000  \n",
       "mean       0.014870     0.127884     1.253131  \n",
       "std        0.671664     0.334071     4.543167  \n",
       "min       -4.444444     0.000000    -1.000000  \n",
       "25%       -0.277778     0.000000    -1.000000  \n",
       "50%        0.000000     0.000000     0.000000  \n",
       "75%        0.277778     0.000000     0.000000  \n",
       "max        6.666667     1.000000    19.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_danger.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Showing convex hulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:21.258667Z",
     "start_time": "2025-02-01T18:48:21.249980Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:21.832752Z",
     "start_time": "2025-02-01T18:48:21.685594Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16608/2564165959.py:3: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  colors = plt.cm.get_cmap(\"tab10\", len(unique_clusters))  # Set of distinct colors for clusters\n"
     ]
    }
   ],
   "source": [
    "def plot_convex_hulls(df, clusters, normal_df_points):\n",
    "    unique_clusters = set(clusters)\n",
    "    colors = plt.cm.get_cmap(\"tab10\", len(unique_clusters))  # Set of distinct colors for clusters\n",
    "\n",
    "    fig, ax = plt.subplots()  # Create figure and axis objects\n",
    "\n",
    "    # Plot points first for colorbar\n",
    "    for cluster in unique_clusters:\n",
    "        if cluster == -1:\n",
    "            continue  # Skip noise points\n",
    "        cluster_points = df[df['cluster'] == cluster][['lng', 'lat']].values\n",
    "        ax.scatter(cluster_points[:, 0], cluster_points[:, 1], label=f'Cluster {cluster}', c=[colors(cluster)], s=10)\n",
    "\n",
    "    ax.scatter(normal_df_points['lng'], normal_df_points['lat'], c='gray', alpha=0.5)\n",
    "\n",
    "    # Plot Convex Hulls\n",
    "    for cluster in unique_clusters:\n",
    "        if cluster == -1:\n",
    "            continue  # Skip noise points\n",
    "        cluster_points = df[df['cluster'] == cluster][['lng', 'lat']].values\n",
    "        if len(cluster_points) >= 3:  # Convex hull requires at least 3 points\n",
    "            hull = ConvexHull(cluster_points)\n",
    "            hull_points = np.append(hull.vertices, hull.vertices[0])  # Close the loop\n",
    "            ax.plot(cluster_points[hull_points, 0], cluster_points[hull_points, 1], 'r-')\n",
    "\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    ax.set_title('DBSCAN Clustering of Geospatial Data with Convex Hulls')\n",
    "\n",
    "    # Create colorbar using scatter points\n",
    "    cb = fig.colorbar(plt.cm.ScalarMappable(cmap=\"tab10\", norm=plt.Normalize(vmin=min(unique_clusters), vmax=max(unique_clusters))),\n",
    "                      ax=ax, label='Cluster')\n",
    "    \n",
    "    # Save the plot\n",
    "    # Define the path to save the plot\n",
    "    plot_save_path = os.path.join(PLOT_FOLDER_PATH, \"DBSCAN_Clustering_of_Geospatial_Data_with_Convex_Hulls\")\n",
    "    plt.savefig(plot_save_path, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_convex_hulls(df_danger_cluster, clusters, df[df['isProblem'] == 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get specific **Cluster's BBOX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: {'min_lng': 22.384585, 'max_lng': 22.3870483, 'min_lat': 37.5102516, 'max_lat': 37.51159}\n",
      "Cluster 1: {'min_lng': 22.3874233, 'max_lng': 22.3875216, 'min_lat': 37.5106983, 'max_lat': 37.5108166}\n",
      "Cluster 2: {'min_lng': 22.3868549, 'max_lng': 22.3870566, 'min_lat': 37.5103233, 'max_lat': 37.5105766}\n",
      "Cluster 3: {'min_lng': 22.3839199, 'max_lng': 22.3841449, 'min_lat': 37.5111466, 'max_lat': 37.5112433}\n",
      "Cluster 4: {'min_lng': 22.3842799, 'max_lng': 22.3846183, 'min_lat': 37.5108516, 'max_lat': 37.5110883}\n",
      "Cluster 5: {'min_lng': 22.3833466, 'max_lng': 22.3834666, 'min_lat': 37.5121433, 'max_lat': 37.51235}\n",
      "Cluster 6: {'min_lng': 22.3835516, 'max_lng': 22.3836183, 'min_lat': 37.5140999, 'max_lat': 37.5145033}\n",
      "Cluster 7: {'min_lng': 22.3814849, 'max_lng': 22.3816016, 'min_lat': 37.5184116, 'max_lat': 37.5186266}\n",
      "Cluster 8: {'min_lng': 22.3822883, 'max_lng': 22.3824266, 'min_lat': 37.5191233, 'max_lat': 37.5194066}\n",
      "Cluster 9: {'min_lng': 22.3803183, 'max_lng': 22.380515, 'min_lat': 37.52059, 'max_lat': 37.5209333}\n",
      "Cluster 10: {'min_lng': 22.3804933, 'max_lng': 22.3807333, 'min_lat': 37.521175, 'max_lat': 37.5217549}\n",
      "Cluster 11: {'min_lng': 22.3785466, 'max_lng': 22.3789333, 'min_lat': 37.5222833, 'max_lat': 37.5225433}\n",
      "Cluster 12: {'min_lng': 22.377735, 'max_lng': 22.3781383, 'min_lat': 37.5250533, 'max_lat': 37.5252883}\n",
      "Cluster 13: {'min_lng': 22.37584, 'max_lng': 22.3759533, 'min_lat': 37.5227833, 'max_lat': 37.5232233}\n",
      "Cluster 14: {'min_lng': 22.3735733, 'max_lng': 22.373845, 'min_lat': 37.5210816, 'max_lat': 37.5212716}\n",
      "Cluster 15: {'min_lng': 22.3728549, 'max_lng': 22.3731483, 'min_lat': 37.520865, 'max_lat': 37.5210016}\n",
      "Cluster 16: {'min_lng': 22.3729149, 'max_lng': 22.373, 'min_lat': 37.5282783, 'max_lat': 37.5285433}\n",
      "Cluster 17: {'min_lng': 22.3729166, 'max_lng': 22.3731783, 'min_lat': 37.5286, 'max_lat': 37.5290066}\n",
      "Cluster 18: {'min_lng': 22.3712416, 'max_lng': 22.3715549, 'min_lat': 37.5306633, 'max_lat': 37.5312666}\n",
      "Cluster 19: {'min_lng': 22.3723283, 'max_lng': 22.3723533, 'min_lat': 37.5318199, 'max_lat': 37.5321216}\n"
     ]
    }
   ],
   "source": [
    "def get_bbox_of_clusters(df, clusters):\n",
    "    cluster_bboxes = {}\n",
    "\n",
    "    # Iterate over unique clusters (excluding -1 for noise)\n",
    "    unique_clusters = sorted(set(clusters) - {-1})  # Exclude noise points (-1)\n",
    "\n",
    "    for cluster in unique_clusters:\n",
    "        # Filter the points of the current cluster\n",
    "        cluster_points = df[df['cluster'] == cluster][['lng', 'lat']]\n",
    "        \n",
    "        # Get the minimum and maximum lng and lat for the bounding box\n",
    "        min_lng = cluster_points['lng'].min()\n",
    "        max_lng = cluster_points['lng'].max()\n",
    "        min_lat = cluster_points['lat'].min()\n",
    "        max_lat = cluster_points['lat'].max()\n",
    "\n",
    "        # Store the bounding box for the current cluster\n",
    "        cluster_bboxes[cluster] = {\n",
    "            'min_lng': min_lng,\n",
    "            'max_lng': max_lng,\n",
    "            'min_lat': min_lat,\n",
    "            'max_lat': max_lat\n",
    "        }\n",
    "\n",
    "    return cluster_bboxes\n",
    "\n",
    "cluster_bboxes = get_bbox_of_clusters(df_danger_cluster, clusters)\n",
    "\n",
    "# Display the bounding boxes for each cluster\n",
    "for cluster, bbox in cluster_bboxes.items():\n",
    "    print(f\"Cluster {cluster}: {bbox}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:29.581721Z",
     "start_time": "2025-02-01T18:48:29.577151Z"
    },
    "collapsed": false
   },
   "source": [
    "### Prepare the DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:29.755180Z",
     "start_time": "2025-02-01T18:48:29.750637Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       vehicleId        lat        lng      dateStoredHuman     bearing  \\\n",
      "0              1  37.510833  22.385710  2024-06-06 17:02:17  137.402376   \n",
      "1              1  37.510603  22.385977  2024-06-06 17:02:20  312.778670   \n",
      "2              1  37.510640  22.385927  2024-06-06 17:02:25  351.785725   \n",
      "3              1  37.510750  22.385907  2024-06-06 17:02:31  307.481149   \n",
      "4              1  37.510877  22.385698  2024-06-06 17:02:37  318.388767   \n",
      "...          ...        ...        ...                  ...         ...   \n",
      "28443         20  37.531460  22.369768  2025-03-06 13:09:13  231.663210   \n",
      "28444         20  37.531275  22.369473  2025-03-06 13:09:15  235.207818   \n",
      "28445         20  37.531122  22.369195  2025-03-06 13:09:19  278.389323   \n",
      "28446         20  37.531148  22.368967  2025-03-06 13:09:21  294.596339   \n",
      "28447         20  37.531243  22.368705  2025-03-06 13:09:24         NaN   \n",
      "\n",
      "      orientation  seconds_diff  trip_id  \n",
      "0       Southeast           0.0        0  \n",
      "1       Northwest           3.0        0  \n",
      "2           North           5.0        0  \n",
      "3       Northwest           6.0        0  \n",
      "4       Northwest           6.0        0  \n",
      "...           ...           ...      ...  \n",
      "28443   Southwest           4.0       11  \n",
      "28444   Southwest           2.0       11  \n",
      "28445        West           4.0       11  \n",
      "28446   Northwest           2.0       11  \n",
      "28447         NaN           3.0       11  \n",
      "\n",
      "[28448 rows x 8 columns]\n",
      "The trip_id with the most rows for vehicleId 1 is: 64\n"
     ]
    }
   ],
   "source": [
    "# *Get specific columns \n",
    "_ = merged_dfs.copy()\n",
    "bearings_df = _[['vehicleId', 'lat', 'lng', 'dateStoredHuman' ,'bearing', 'orientation', 'seconds_diff', 'trip_id']]\n",
    "print(bearings_df)\n",
    "\n",
    "# Filter for vehicleId == 1\n",
    "df_vehicle1 = df[df['vehicleId'] == 1]\n",
    "\n",
    "# Count occurrences of each trip_id\n",
    "trip_counts = df_vehicle1['trip_id'].value_counts()\n",
    "\n",
    "# Get the trip_id with the highest count\n",
    "most_frequent_trip_id = trip_counts.idxmax()\n",
    "\n",
    "# Display the result\n",
    "print(f\"The trip_id with the most rows for vehicleId 1 is: {most_frequent_trip_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get trip_id's rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:29.911737Z",
     "start_time": "2025-02-01T18:48:29.907023Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     vehicleId        lat        lng  velocity      dateStoredHuman  \\\n",
      "946          1  37.510722  22.387033      16.0  2024-06-08 17:32:23   \n",
      "947          1  37.510692  22.387185       8.0  2024-06-08 17:32:30   \n",
      "948          1  37.510670  22.387042       9.0  2024-06-08 17:32:38   \n",
      "949          1  37.510645  22.386773      22.0  2024-06-08 17:32:41   \n",
      "950          1  37.510685  22.386552      34.0  2024-06-08 17:32:43   \n",
      "\n",
      "     seconds_diff  trip_id  distance_m     bearing orientation  bearing_diff  \\\n",
      "946           0.0       64        0.00  103.998723        East          0.00   \n",
      "947           7.0       64       13.82  259.248208        West        155.25   \n",
      "948           8.0       64       12.90  263.300439        West          4.05   \n",
      "949           3.0       64       23.88  282.783117        West         19.48   \n",
      "950           2.0       64       20.10  277.535628        West          5.25   \n",
      "\n",
      "     velocity_diff  acceleration  isProblem  \n",
      "946          -40.0      0.000000          0  \n",
      "947           -8.0     -0.317460          0  \n",
      "948            1.0      0.034722          0  \n",
      "949           13.0      1.203704          0  \n",
      "950           12.0      1.666667          0  \n"
     ]
    }
   ],
   "source": [
    "print(df[(df['vehicleId'] == 1) & (df['trip_id'] == most_frequent_trip_id)].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot real **directional spread**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1️⃣ Violin Plot (Distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:30.464254Z",
     "start_time": "2025-02-01T18:48:30.459088Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to ./Plots/\n"
     ]
    }
   ],
   "source": [
    "# Convert to radians for circular statistics\n",
    "bearing_diff_rad = np.deg2rad(merged_dfs['bearing_diff'])\n",
    "\n",
    "# Compute circular mean and circular standard deviation\n",
    "circular_mean_rad = circmean(bearing_diff_rad, high=np.pi, low=-np.pi)\n",
    "circular_std_rad = circstd(bearing_diff_rad, high=np.pi, low=-np.pi)\n",
    "\n",
    "# Convert back to degrees for plotting\n",
    "circular_mean_deg = np.rad2deg(circular_mean_rad)\n",
    "circular_std_deg = np.rad2deg(circular_std_rad)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Create the violin plot\n",
    "sns.violinplot(x=merged_dfs['bearing_diff'], inner=\"quartile\", color=\"lightblue\")\n",
    "\n",
    "# Mark the circular mean and circular standard deviation\n",
    "plt.axvline(x=circular_mean_deg, color='green', linestyle='-', label=f'Circular Mean ({circular_mean_deg:.2f}°)')\n",
    "plt.axvline(x=circular_mean_deg + circular_std_deg, color='orange', linestyle='--', label=f'+1σ ({(circular_mean_deg + circular_std_deg):.2f}°)')\n",
    "plt.axvline(x=circular_mean_deg - circular_std_deg, color='orange', linestyle='--', label=f'-1σ ({(circular_mean_deg - circular_std_deg):.2f}°)')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Bearing Difference (Degrees)')\n",
    "plt.title('Violin Plot: Circular Stats of Bearing Difference')\n",
    "\n",
    "# Show legend\n",
    "plt.legend()\n",
    "\n",
    "# Save and display\n",
    "plt.savefig(PLOT_FOLDER_PATH, bbox_inches='tight')\n",
    "print(f\"Plot saved to {PLOT_FOLDER_PATH}\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print((merged_dfs['bearing_diff'] < 0).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1️⃣ Polar Plot: Bearing Difference Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polar plot saved to ./Plots/Polar Plot\n"
     ]
    }
   ],
   "source": [
    "# Convert to radians and wrap angles to [0, 2π]\n",
    "bearing_diff_rad = np.deg2rad(merged_dfs['bearing_diff'] % 360)\n",
    "\n",
    "# Define number of bins (adjust based on resolution you want)\n",
    "num_bins = 36  # 10-degree bins\n",
    "\n",
    "# Create histogram\n",
    "counts, bin_edges = np.histogram(bearing_diff_rad, bins=num_bins)\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "# Create polar plot\n",
    "plt.figure(figsize=(6, 6))\n",
    "ax = plt.subplot(111, polar=True)\n",
    "\n",
    "# Plot histogram as bars\n",
    "bars = ax.bar(bin_centers, counts, width=(2 * np.pi / num_bins), bottom=0.0, color='lightblue', edgecolor='k')\n",
    "\n",
    "# Optional: highlight circular mean\n",
    "from scipy.stats import circmean\n",
    "circular_mean_rad = circmean(bearing_diff_rad, high=2*np.pi, low=0)\n",
    "ax.plot([circular_mean_rad, circular_mean_rad], [0, max(counts)], color='red', linestyle='--', linewidth=2, label='Circular Mean')\n",
    "\n",
    "# Format and show\n",
    "ax.set_theta_zero_location('N')  # 0° at the top\n",
    "ax.set_theta_direction(-1)       # Clockwise\n",
    "plt.title(\"Polar Plot: Bearing Difference Distribution\")\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# Save and display\n",
    "# Define the path to save the plot\n",
    "plot_save_path = os.path.join(PLOT_FOLDER_PATH, \"Polar Plot\")\n",
    "plt.savefig(plot_save_path, bbox_inches='tight')\n",
    "print(f\"Polar plot saved to {plot_save_path}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:30.648854Z",
     "start_time": "2025-02-01T18:48:30.643996Z"
    },
    "collapsed": false
   },
   "source": [
    "###  2️⃣ Boxplot (Detect Outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boxplot saved to ./Plots/\n"
     ]
    }
   ],
   "source": [
    "# Convert to radians for circular statistics\n",
    "bearing_diff_rad = np.deg2rad(merged_dfs['bearing_diff'])\n",
    "\n",
    "# Compute circular mean and circular standard deviation\n",
    "circular_mean_rad = circmean(bearing_diff_rad, high=np.pi, low=-np.pi)\n",
    "circular_std_rad = circstd(bearing_diff_rad, high=np.pi, low=-np.pi)\n",
    "\n",
    "# Convert back to degrees for plotting\n",
    "circular_mean_deg = np.rad2deg(circular_mean_rad)\n",
    "circular_std_deg = np.rad2deg(circular_std_rad)\n",
    "\n",
    "# Create the boxplot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(x=merged_dfs['bearing_diff'], color='lightgreen', fliersize=3)\n",
    "\n",
    "# Overlay circular mean and ±1σ\n",
    "plt.axvline(x=circular_mean_deg, color='blue', linestyle='-', label=f'Circular Mean ({circular_mean_deg:.2f}°)')\n",
    "plt.axvline(x=circular_mean_deg + circular_std_deg, color='red', linestyle='--', label=f'+1σ ({(circular_mean_deg + circular_std_deg):.2f}°)')\n",
    "plt.axvline(x=circular_mean_deg - circular_std_deg, color='red', linestyle='--', label=f'-1σ ({(circular_mean_deg - circular_std_deg):.2f}°)')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Bearing Difference (Degrees)')\n",
    "plt.title('Boxplot: Circular Stats of Bearing Difference')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save and display\n",
    "plot_save_path = PLOT_FOLDER_PATH.replace(\".png\", \"_boxplot.png\")\n",
    "plt.savefig(plot_save_path, bbox_inches='tight')\n",
    "print(f\"Boxplot saved to {plot_save_path}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3️⃣ Color by Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to ./Plots/Scatter_bearings_vs_seconds_diff_density.png\n"
     ]
    }
   ],
   "source": [
    "x = merged_dfs['seconds_diff']\n",
    "y = merged_dfs['bearing_diff']\n",
    "\n",
    "# Calculate point density\n",
    "xy = np.vstack([x, y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(x, y, c=z, cmap='viridis', s=50, edgecolors='none', alpha=0.8)\n",
    "plt.colorbar(scatter, label='Point Density')\n",
    "plt.title('Scatter Plot of Bearing Difference vs. Seconds Difference')\n",
    "plt.xlabel('Seconds Difference')\n",
    "plt.ylabel('Bearing Difference')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save\n",
    "plot_save_path = os.path.join(PLOT_FOLDER_PATH, \"Scatter_bearings_vs_seconds_diff_density.png\")\n",
    "plt.savefig(plot_save_path, bbox_inches='tight')\n",
    "print(f\"Plot saved to {plot_save_path}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4️⃣ Scatter + Trend Line + Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static plot saved to ./Plots/Enhanced_Scatter_with_LOESS.png\n"
     ]
    }
   ],
   "source": [
    "x = merged_dfs['seconds_diff']\n",
    "y = merged_dfs['bearing_diff']\n",
    "\n",
    "# Calculate density\n",
    "xy = np.vstack([x, y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "# LOWESS smoothing\n",
    "lowess = sm.nonparametric.lowess\n",
    "smoothed = lowess(y, x, frac=0.2)  # Adjust frac for smoothness\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Scatter colored by density\n",
    "scatter = plt.scatter(x, y, c=z, cmap='viridis', s=40, edgecolors='none', alpha=0.7, label='Data Points')\n",
    "\n",
    "# LOWESS line\n",
    "plt.plot(smoothed[:, 0], smoothed[:, 1], color='red', linewidth=2, label='LOWESS Trend')\n",
    "\n",
    "# Optional thresholds (customize as needed)\n",
    "plt.axhline(y=45, color='orange', linestyle='--', linewidth=1, label='Upper Threshold (45°)')\n",
    "plt.axhline(y=-45, color='orange', linestyle='--', linewidth=1, label='Lower Threshold (-45°)')\n",
    "\n",
    "plt.title('Bearing Difference vs. Seconds Difference (with Trend)')\n",
    "plt.xlabel('Seconds Difference')\n",
    "plt.ylabel('Bearing Difference')\n",
    "plt.colorbar(scatter, label='Point Density')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save\n",
    "plot_save_path = os.path.join(PLOT_FOLDER_PATH, \"Enhanced_Scatter_with_LOESS.png\")\n",
    "plt.savefig(plot_save_path, bbox_inches='tight')\n",
    "print(f\"Static plot saved to {plot_save_path}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5️⃣ KDE Plot for Angular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static plot saved to ./Plots/KDE_of_Bearing_Differences_(Wrapped).png\n"
     ]
    }
   ],
   "source": [
    "# Wrap angles between -180 and 180\n",
    "angles_deg = merged_dfs['bearing_diff']\n",
    "angles_deg_wrapped = ((angles_deg + 180) % 360) - 180\n",
    "\n",
    "# KDE estimation\n",
    "kde = gaussian_kde(angles_deg_wrapped)\n",
    "x_vals = np.linspace(-180, 180, 360)\n",
    "kde_vals = kde(x_vals)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x_vals, kde_vals, color='purple', label='KDE')\n",
    "plt.axvline(x=circular_mean_deg, color='blue', linestyle='-', label='Circular Mean')\n",
    "plt.axvline(x=circular_mean_deg + circular_std_deg, color='red', linestyle='--', label='+1σ')\n",
    "plt.axvline(x=circular_mean_deg - circular_std_deg, color='red', linestyle='--', label='-1σ')\n",
    "plt.title(\"KDE of Bearing Differences (Wrapped)\")\n",
    "plt.xlabel(\"Bearing Difference (Degrees)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save\n",
    "plot_save_path = os.path.join(PLOT_FOLDER_PATH, \"KDE_of_Bearing_Differences_(Wrapped).png\")\n",
    "plt.savefig(plot_save_path, bbox_inches='tight')\n",
    "print(f\"Static plot saved to {plot_save_path}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6️⃣ Circular Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static plot saved to ./Plots/Circular_Heatmap.png\n"
     ]
    }
   ],
   "source": [
    "# Create 2D histogram: angle + magnitude or time\n",
    "angle_bins = np.linspace(-np.pi, np.pi, 36)\n",
    "magnitude_bins = np.linspace(0, merged_dfs['bearing_diff'].max(), 20)\n",
    "\n",
    "H, _, _ = np.histogram2d(bearing_diff_rad, merged_dfs['bearing_diff'], bins=[angle_bins, magnitude_bins])\n",
    "\n",
    "theta, r = np.meshgrid(angle_bins[:-1], magnitude_bins[:-1])\n",
    "plt.figure(figsize=(6, 6))\n",
    "ax = plt.subplot(111, polar=True)\n",
    "heatmap = ax.pcolormesh(theta, r, H.T, cmap='plasma')\n",
    "plt.colorbar(heatmap, label='Density')\n",
    "ax.set_title(\"Circular Heatmap\")\n",
    "plt.tight_layout()\n",
    "# Save\n",
    "plot_save_path = os.path.join(PLOT_FOLDER_PATH, \"Circular_Heatmap.png\")\n",
    "plt.savefig(plot_save_path, bbox_inches='tight')\n",
    "print(f\"Static plot saved to {plot_save_path}\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7️⃣ Combine Plots in a Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static plot saved to ./Plots/Various_Views_of_Bearing_Differences\n"
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "sns.boxplot(x=merged_dfs['bearing_diff'], ax=axs[0, 0])\n",
    "sns.violinplot(x=merged_dfs['bearing_diff'], ax=axs[0, 1])\n",
    "sns.histplot(merged_dfs['bearing_diff'], bins=30, kde=True, ax=axs[1, 0])\n",
    "axs[1, 1].hist(bearing_diff_rad, bins=36)\n",
    "axs[1, 1].set_title('Histogram (Radians)')\n",
    "\n",
    "fig.suptitle(\"Various Views of Bearing Differences\")\n",
    "plt.tight_layout()\n",
    "# Save\n",
    "plot_save_path = os.path.join(PLOT_FOLDER_PATH, \"Various_Views_of_Bearing_Differences\")\n",
    "plt.savefig(plot_save_path, bbox_inches='tight')\n",
    "print(f\"Static plot saved to {plot_save_path}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot bearings vs 10 seconds_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16608/3279668019.py:17: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  colors = plt.cm.get_cmap('tab20', 20)  # Using the 'tab20' colormap\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame and take only the first 20 rows\n",
    "filtered_df = merged_dfs[merged_dfs['seconds_diff'] <= 10].head(20)\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Scatter plot (swapped axes)\n",
    "ax.scatter(\n",
    "    filtered_df['bearing_diff'],\n",
    "    filtered_df['seconds_diff'],\n",
    "    alpha=0.6,\n",
    "    edgecolors='w',\n",
    "    label='Points'\n",
    ")\n",
    "\n",
    "# Generate a list of 20 distinct colors using a colormap\n",
    "colors = plt.cm.get_cmap('tab20', 20)  # Using the 'tab20' colormap\n",
    "\n",
    "# Plot segments with changing color for each segment\n",
    "for i in range(len(filtered_df) - 1):\n",
    "    # Get the x and y values for the two points\n",
    "    x_start = filtered_df['bearing_diff'].iloc[i]\n",
    "    y_start = filtered_df['seconds_diff'].iloc[i]\n",
    "    x_end = filtered_df['bearing_diff'].iloc[i + 1]\n",
    "    y_end = filtered_df['seconds_diff'].iloc[i + 1]\n",
    "\n",
    "    # Assign a unique color for each segment from the 'tab20' colormap\n",
    "    color = colors(i)  # Get a different color for each segment\n",
    "\n",
    "    # Plot each segment with its own color\n",
    "    ax.plot([x_start, x_end], [y_start, y_end], color=color, lw=2)\n",
    "\n",
    "# Add incremental labels\n",
    "for i, (x, y) in enumerate(zip(filtered_df['bearing_diff'], filtered_df['seconds_diff'])):\n",
    "    ax.text(x + 0.5, y + 0.1, str(i), fontsize=9, color='black')\n",
    "\n",
    "# Prepare the orientation labels\n",
    "orientation_list = [f\"{i+1}. {orientation}\" for i, orientation in enumerate(filtered_df['orientation'])]\n",
    "\n",
    "# Prepare cell text for the table\n",
    "cell_text = [[orientation] for orientation in orientation_list]\n",
    "\n",
    "# Add the table on the right side of the plot (without color)\n",
    "table = ax.table(cellText=cell_text,\n",
    "                 colLabels=['Orientation'],\n",
    "                 loc='right',\n",
    "                 cellLoc='center',\n",
    "                 colColours=['lightgray'],  # Keep the header background color if desired\n",
    "                 bbox=[1.05, 0, 0.2, 1])  # Adjust bbox for position and size\n",
    "\n",
    "# Labels and title\n",
    "ax.set_title('Bearing Difference vs Seconds Difference (<= 10 seconds)')\n",
    "ax.set_xlabel('Bearing Diff')\n",
    "ax.set_ylabel('Seconds Diff')\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plot_save_path = os.path.join(PLOT_FOLDER_PATH, \"bearings_vs_seconds_diff.png\")\n",
    "plt.savefig(plot_save_path, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trajectory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter trips for calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      vehicleId  trip_id  count\n",
      "0             1        0     13\n",
      "1             1        1      2\n",
      "2             1        2      6\n",
      "3             1        3      4\n",
      "4             1        4      1\n",
      "...         ...      ...    ...\n",
      "1422         20        7      3\n",
      "1423         20        8     89\n",
      "1424         20        9     11\n",
      "1425         20       10      7\n",
      "1426         20       11     10\n",
      "\n",
      "[1427 rows x 3 columns]\n",
      "      vehicleId  trip_id  total_distance_m\n",
      "0             1        0            291.50\n",
      "1             1        1              3.88\n",
      "2             1        2             99.97\n",
      "3             1        3             44.61\n",
      "4             1        4              0.00\n",
      "...         ...      ...               ...\n",
      "1422         20        7             21.63\n",
      "1423         20        8           1597.54\n",
      "1424         20        9            253.65\n",
      "1425         20       10             40.92\n",
      "1426         20       11            239.76\n",
      "\n",
      "[1427 rows x 3 columns]\n",
      "Row difference excluded: 28448 - 25043 = 3405\n"
     ]
    }
   ],
   "source": [
    "# !Ensure trip_id has at least 6 rows, otherwise, do not calculate any slaloms\n",
    "trip_counts = merged_dfs.groupby(['vehicleId', 'trip_id']).size().reset_index(name='count')\n",
    "print(trip_counts)\n",
    "\n",
    "trip_distances = merged_dfs.groupby(['vehicleId', 'trip_id'])['distance_m'].sum().reset_index(name='total_distance_m')\n",
    "print(trip_distances)\n",
    "\n",
    "# *Filter only those trip_ids with more than 10 rows distance traveled > 50\n",
    "valid_trips = trip_counts[(trip_counts['count'] > 10) & (trip_distances['total_distance_m'] > 50.00)]\n",
    "\n",
    "filtered_merged_dfs = merged_dfs.copy()\n",
    "filtered_merged_dfs = pd.merge(merged_dfs, valid_trips[['vehicleId', 'trip_id']], on=['vehicleId', 'trip_id'], how='inner')\n",
    "print(f\"Row difference excluded: {len(merged_dfs)} - {len(filtered_merged_dfs)} = {len(merged_dfs) - len(filtered_merged_dfs)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot random vehicle ids and trip_ids **exclude VehicleId: 1 because it has problematic data points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 - vehicleId: 7, trip_id: 362\n",
      "Plot saved to ./Plots/Coordinates_for_Vehicle_7_-_Trip_362_-_40_Data_Points.png\n",
      "Iteration 2 - vehicleId: 7, trip_id: 45\n",
      "Plot saved to ./Plots/Coordinates_for_Vehicle_7_-_Trip_45_-_23_Data_Points.png\n",
      "Iteration 3 - vehicleId: 7, trip_id: 186\n",
      "Plot saved to ./Plots/Coordinates_for_Vehicle_7_-_Trip_186_-_102_Data_Points.png\n",
      "Iteration 4 - vehicleId: 9, trip_id: 256\n",
      "Plot saved to ./Plots/Coordinates_for_Vehicle_9_-_Trip_256_-_20_Data_Points.png\n",
      "Iteration 5 - vehicleId: 1, trip_id: 53\n",
      "Plot saved to ./Plots/Coordinates_for_Vehicle_1_-_Trip_53_-_44_Data_Points.png\n",
      "Iteration 6 - vehicleId: 9, trip_id: 23\n",
      "Plot saved to ./Plots/Coordinates_for_Vehicle_9_-_Trip_23_-_280_Data_Points.png\n",
      "Iteration 7 - vehicleId: 7, trip_id: 336\n",
      "Plot saved to ./Plots/Coordinates_for_Vehicle_7_-_Trip_336_-_16_Data_Points.png\n",
      "Iteration 8 - vehicleId: 9, trip_id: 39\n",
      "Plot saved to ./Plots/Coordinates_for_Vehicle_9_-_Trip_39_-_25_Data_Points.png\n",
      "Iteration 9 - vehicleId: 7, trip_id: 88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16608/2752486889.py:17: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(8, 6))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to ./Plots/Coordinates_for_Vehicle_7_-_Trip_88_-_227_Data_Points.png\n",
      "Iteration 10 - vehicleId: 5, trip_id: 1\n",
      "Plot saved to ./Plots/Coordinates_for_Vehicle_5_-_Trip_1_-_75_Data_Points.png\n"
     ]
    }
   ],
   "source": [
    "def random_ID(df):\n",
    "    trip_counts = df.groupby(['vehicleId', 'trip_id']).size().reset_index(name='count')\n",
    "    valid_trip_counts = trip_counts[trip_counts['count'] >= 10]\n",
    "    selected_trip = valid_trip_counts.sample(1).iloc[0]\n",
    "    return selected_trip['vehicleId'], selected_trip['trip_id']\n",
    "\n",
    "# Loop through 10 times\n",
    "for i in range(10):\n",
    "    vehicle_id, trip_id = random_ID(merged_dfs)\n",
    "    print(f'Iteration {i+1} - vehicleId: {vehicle_id}, trip_id: {trip_id}')\n",
    "\n",
    "    # Filter the DataFrame\n",
    "    filtered_df = merged_dfs[(merged_dfs['vehicleId'] == vehicle_id) & (merged_dfs['trip_id'] == trip_id)]\n",
    "    num_rows = len(filtered_df)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(filtered_df['lng'], filtered_df['lat'], c='blue')\n",
    "    plt.scatter(filtered_df['lng'], filtered_df['lat'], c='blue', marker='o', label=f'Vehicle {vehicle_id} - Trip {trip_id}')\n",
    "    \n",
    "    # Create title and file name\n",
    "    title = f'Coordinates for Vehicle {vehicle_id} - Trip {trip_id} - {num_rows} Data Points'\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Save plot with title-based filename\n",
    "    file_name = title.replace(' ', '_') + \".png\"\n",
    "    plot_save_path = os.path.join(PLOT_FOLDER_PATH, file_name)\n",
    "    plt.savefig(plot_save_path, bbox_inches='tight')\n",
    "    print(f\"Plot saved to {plot_save_path}\")\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save DF to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mDataFrame stored to ./visualize_dangers.csv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "visualize_dangers_path = \"./visualize_dangers.csv\"\n",
    "merged_dfs.to_csv(visualize_dangers_path, index=False)\n",
    "print(Fore.GREEN + f\"DataFrame stored to {visualize_dangers_path}\" + Style.RESET_ALL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGIS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
