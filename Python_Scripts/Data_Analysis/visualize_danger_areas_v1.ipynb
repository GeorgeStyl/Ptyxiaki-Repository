{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:02.444705Z",
     "start_time": "2025-02-01T18:48:02.442519Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.neighbors import KernelDensity, BallTree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial import ConvexHull\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# File loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:02.670714Z",
     "start_time": "2025-02-01T18:48:02.667030Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"vehicleId\", \n",
    "    \"lat\", \n",
    "    \"lng\", \n",
    "    \"dateStored\", \n",
    "    \"velocity\",\n",
    "    \"odometer\", \n",
    "    \"engineVoltage\", \n",
    "    \"dateStoredHuman\", \n",
    "    \"dateOnlyStoredHuman\",    \n",
    "    \"timeOnly\",\n",
    "    \"orientation\", \n",
    "    \"seconds_diff\", \n",
    "    \"acceleration\",\n",
    "    \"isProblem\"\n",
    "]\n",
    "\n",
    "\n",
    "input_dir   = '../../DataSets/API_Responses/Vehicle_Data/'\n",
    "filename    = \"all_vehicle_responses.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:03.383127Z",
     "start_time": "2025-02-01T18:48:03.325978Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   vehicleId        lat        lng           dateStored  velocity  odometer  \\\n",
      "0          1  38.034458  23.748177  2024-05-22 12:57:05       0.0       0.0   \n",
      "1          1  38.034598  23.748143  2024-05-22 13:04:41       6.0       0.0   \n",
      "2          1  38.034633  23.748132  2024-05-22 13:05:05       0.0       0.0   \n",
      "3          1  38.034667  23.748163  2024-05-22 13:08:53       0.0       0.0   \n",
      "4          1  38.034713  23.748122  2024-05-22 13:15:24       8.0       0.0   \n",
      "\n",
      "   engineVoltage      dateStoredHuman dateOnlyStoredHuman  timeOnly  \\\n",
      "0            0.0  2024-05-22 15:57:05          2024-05-22  15:57:05   \n",
      "1            0.0  2024-05-22 16:04:41          2024-05-22  16:04:41   \n",
      "2            0.0  2024-05-22 16:05:05          2024-05-22  16:05:05   \n",
      "3            0.0  2024-05-22 16:08:53          2024-05-22  16:08:53   \n",
      "4            0.0  2024-05-22 16:15:24          2024-05-22  16:15:24   \n",
      "\n",
      "  orientation  seconds_diff  acceleration  isProblem  \n",
      "0   Northwest           NaN      0.000000          0  \n",
      "1   Northwest         456.0      0.013158          0  \n",
      "2   Northwest          24.0     -0.250000          0  \n",
      "3        West         228.0      0.000000          0  \n",
      "4        East         391.0      0.020460          0  \n"
     ]
    }
   ],
   "source": [
    "def merge_csv_file(input_dir, filename, columns):\n",
    "    input_file = os.path.join(input_dir, filename)\n",
    "\n",
    "    if not os.path.exists(input_file):\n",
    "        raise FileNotFoundError(f\"File '{filename}' not found in directory '{input_dir}'\")\n",
    "\n",
    "    try:\n",
    "        # Read the CSV while allowing missing columns\n",
    "        df = pd.read_csv(input_file, usecols=lambda x: x.strip() in columns, encoding='utf-8')\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error reading '{input_file}': {e}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "merged_df = merge_csv_file(input_dir, filename, columns)\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set **Bounding Box** only for **Τρίπολη**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "latMin = 37.49764419371479\n",
    "latMax = 37.56244081620044\n",
    "lngMin = 22.344992459074458\n",
    "lngMax = 22.521463853839485\n",
    "\n",
    "\n",
    "query_filter = 'lat >= ' +str(latMin)+' & lat <= ' + str(latMax) + ' & lng >= ' +str(lngMin)+ ' & lng <= '+str(lngMax)\n",
    "veh_data_tripoli = merged_df.query( query_filter ).copy(True)\n",
    "merged_df = veh_data_tripoli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of        vehicleId        lat        lng           dateStored  velocity  \\\n",
       "89             1  37.510833  22.385710  2024-06-06 14:02:17       0.0   \n",
       "90             1  37.510603  22.385977  2024-06-06 14:02:20       0.0   \n",
       "91             1  37.510640  22.385927  2024-06-06 14:02:25       6.0   \n",
       "92             1  37.510750  22.385907  2024-06-06 14:02:31       7.0   \n",
       "93             1  37.510877  22.385698  2024-06-06 14:02:37      26.0   \n",
       "...          ...        ...        ...                  ...       ...   \n",
       "48956         19  37.510782  22.386343  2024-07-31 13:47:23       6.0   \n",
       "48957         19  37.510762  22.386272  2024-07-31 13:48:38       0.0   \n",
       "48958         19  37.510742  22.386345  2024-07-31 13:50:20       8.0   \n",
       "48959         19  37.510752  22.386367  2024-07-31 13:50:29       6.0   \n",
       "48960         19  37.510773  22.386430  2024-07-31 13:51:29       0.0   \n",
       "\n",
       "       odometer  engineVoltage      dateStoredHuman dateOnlyStoredHuman  \\\n",
       "89          0.0          0.280  2024-06-06 17:02:17          2024-06-06   \n",
       "90          0.0          0.280  2024-06-06 17:02:20          2024-06-06   \n",
       "91          0.0          0.280  2024-06-06 17:02:25          2024-06-06   \n",
       "92          0.0          0.280  2024-06-06 17:02:31          2024-06-06   \n",
       "93          0.0          0.280  2024-06-06 17:02:37          2024-06-06   \n",
       "...         ...            ...                  ...                 ...   \n",
       "48956       0.0          3.750  2024-07-31 16:47:23          2024-07-31   \n",
       "48957       0.0          3.793  2024-07-31 16:48:38          2024-07-31   \n",
       "48958       0.0          0.364  2024-07-31 16:50:20          2024-07-31   \n",
       "48959       0.0          0.269  2024-07-31 16:50:29          2024-07-31   \n",
       "48960       0.0          0.246  2024-07-31 16:51:29          2024-07-31   \n",
       "\n",
       "       timeOnly orientation  seconds_diff  acceleration  isProblem  \n",
       "89     17:02:17   Southeast     1297674.0      0.000000          0  \n",
       "90     17:02:20   Northwest           3.0      0.000000          0  \n",
       "91     17:02:25       North           5.0      1.200000          0  \n",
       "92     17:02:31   Northwest           6.0      0.166667          0  \n",
       "93     17:02:37   Northwest           6.0      3.166667          0  \n",
       "...         ...         ...           ...           ...        ...  \n",
       "48956  16:47:23        West           1.0     -1.000000          1  \n",
       "48957  16:48:38        East          75.0     -0.080000          0  \n",
       "48958  16:50:20   Northeast         102.0      0.078431          0  \n",
       "48959  16:50:29   Northeast           9.0     -0.222222          0  \n",
       "48960  16:51:29        West          60.0     -0.100000          0  \n",
       "\n",
       "[19214 rows x 14 columns]>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:12.258811Z",
     "start_time": "2025-02-01T18:48:12.187714Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Density of problem points on spatial coordinates')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = merged_df\n",
    "df_danger = df[df['isProblem'] == 1]\n",
    "df_danger = df[df['vehicleId'] == 15]\n",
    "\n",
    "\n",
    "sns.set_theme(style=\"ticks\")\n",
    "fig, ax = plt.subplots()\n",
    "#sns.jointplot(x=df_danger['lng'], y=df_danger['lat'], kind=\"hex\", color=\"#4CB391\", ax=ax)\n",
    "ax.hexbin(x=df_danger['lng'], y=df_danger['lat'])\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "\n",
    "plt.gca().xaxis.set_major_formatter(ScalarFormatter())\n",
    "plt.gca().yaxis.set_major_formatter(ScalarFormatter())\n",
    "plt.ticklabel_format(style='plain', axis='both')  # Disable scientific notation\n",
    "\n",
    "\n",
    "ax.set_title('Density of problem points on spatial coordinates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of        vehicleId        lat        lng           dateStored  velocity  \\\n",
       "18647         15  37.510750  22.386272  2024-10-14 23:15:27       0.0   \n",
       "18648         15  37.510823  22.385855  2024-10-14 23:15:28      16.0   \n",
       "18649         15  37.510872  22.385613  2024-10-14 23:15:39      14.0   \n",
       "18650         15  37.510858  22.385625  2024-10-14 23:15:48      13.0   \n",
       "18651         15  37.510848  22.385382  2024-10-14 23:15:53      24.0   \n",
       "...          ...        ...        ...                  ...       ...   \n",
       "20159         15  37.523477  22.376433  2024-11-07 19:45:19      33.0   \n",
       "20160         15  37.524508  22.376960  2024-11-07 19:45:28      51.0   \n",
       "20161         15  37.525552  22.378802  2024-11-07 19:45:50      14.0   \n",
       "20162         15  37.525507  22.378780  2024-11-07 19:45:52      10.0   \n",
       "20163         15  37.525475  22.378782  2024-11-07 19:46:02       0.0   \n",
       "\n",
       "       odometer  engineVoltage      dateStoredHuman dateOnlyStoredHuman  \\\n",
       "18647       0.0          5.271  2024-10-15 02:15:27          2024-10-15   \n",
       "18648       0.0          5.271  2024-10-15 02:15:28          2024-10-15   \n",
       "18649       0.0          5.276  2024-10-15 02:15:39          2024-10-15   \n",
       "18650       0.0          5.277  2024-10-15 02:15:48          2024-10-15   \n",
       "18651       0.0          5.273  2024-10-15 02:15:53          2024-10-15   \n",
       "...         ...            ...                  ...                 ...   \n",
       "20159       0.0          5.218  2024-11-07 21:45:19          2024-11-07   \n",
       "20160       0.0          5.221  2024-11-07 21:45:28          2024-11-07   \n",
       "20161       0.0          5.223  2024-11-07 21:45:50          2024-11-07   \n",
       "20162       0.0          5.223  2024-11-07 21:45:52          2024-11-07   \n",
       "20163       0.0          5.222  2024-11-07 21:46:02          2024-11-07   \n",
       "\n",
       "       timeOnly orientation  seconds_diff  acceleration  isProblem  \n",
       "18647  02:15:27        West    12561096.0      0.000000          0  \n",
       "18648  02:15:28        West           1.0     16.000000          0  \n",
       "18649  02:15:39   Southeast          11.0     -0.181818          0  \n",
       "18650  02:15:48        West           9.0     -0.111111          0  \n",
       "18651  02:15:53        West           5.0      2.200000          0  \n",
       "...         ...         ...           ...           ...        ...  \n",
       "20159  21:45:19       North           1.0      0.000000          0  \n",
       "20160  21:45:28   Northeast           9.0      2.000000          0  \n",
       "20161  21:45:50       South          22.0     -1.681818          1  \n",
       "20162  21:45:52       South           2.0     -2.000000          1  \n",
       "20163  21:46:02       South          10.0     -1.000000          1  \n",
       "\n",
       "[1517 rows x 14 columns]>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_danger.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df15 = df[df[\"vehicleId\"] == 15]\n",
    "df15 = df15.head(500)\n",
    "df15_problem = df15[df15['isProblem'] == 1]\n",
    "plt.plot(df15.index, df15['acceleration'])\n",
    "plt.title('Acceleration vs Index')\n",
    "plt.ylabel('Acceleration')\n",
    "plt.xlabel('Index')\n",
    "plt.scatter(df15_problem.index, df15_problem['acceleration'], color='red')\n",
    "\n",
    "len(df15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:12.613965Z",
     "start_time": "2025-02-01T18:48:12.598846Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "lng",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "lat",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "7fe8a706-0cd7-42cd-a2a7-6c3a258c2b53",
       "rows": [
        [
         "count",
         "29976.0",
         "29976.0"
        ],
        [
         "mean",
         "23.65538837561049",
         "38.01348447275821"
        ],
        [
         "std",
         "0.3421069594858157",
         "0.12470828674560662"
        ],
        [
         "min",
         "22.360795",
         "37.5067816"
        ],
        [
         "25%",
         "23.7599",
         "38.046742475"
        ],
        [
         "50%",
         "23.7608316",
         "38.05068"
        ],
        [
         "75%",
         "23.7614949",
         "38.0508049"
        ],
        [
         "max",
         "23.79282",
         "38.0948583"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lng</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>29976.000000</td>\n",
       "      <td>29976.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>23.655388</td>\n",
       "      <td>38.013484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.342107</td>\n",
       "      <td>0.124708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>22.360795</td>\n",
       "      <td>37.506782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>23.759900</td>\n",
       "      <td>38.046742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.760832</td>\n",
       "      <td>38.050680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.761495</td>\n",
       "      <td>38.050805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>23.792820</td>\n",
       "      <td>38.094858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                lng           lat\n",
       "count  29976.000000  29976.000000\n",
       "mean      23.655388     38.013484\n",
       "std        0.342107      0.124708\n",
       "min       22.360795     37.506782\n",
       "25%       23.759900     38.046742\n",
       "50%       23.760832     38.050680\n",
       "75%       23.761495     38.050805\n",
       "max       23.792820     38.094858"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_danger[['lng', 'lat']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:17.330420Z",
     "start_time": "2025-02-01T18:48:17.325963Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #### MOCK DATA #####\n",
    "#\n",
    "# data = {\n",
    "#     'lng': np.random.uniform(-180, 180, 200),\n",
    "#     'lat': np.random.uniform(-90, 90, 200)\n",
    "# }\n",
    "# df = pd.DataFrame(data)\n",
    "# df_danger = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:17.808617Z",
     "start_time": "2025-02-01T18:48:17.802262Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:18.846543Z",
     "start_time": "2025-02-01T18:48:18.474283Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_71284/2252399618.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_danger.loc[:, 'cluster'] = clusters  # Adding cluster labels to DataFrame\n"
     ]
    }
   ],
   "source": [
    "# Extracting the coordinates\n",
    "coords = df_danger[['lng', 'lat']].values\n",
    "\n",
    "# Standardizing the data for better clustering performance\n",
    "scaler = StandardScaler()\n",
    "coords_scaled = scaler.fit_transform(coords)\n",
    "\n",
    "# Applying DBSCAN\n",
    "dbscan = DBSCAN(eps=0.02, min_samples=4)  # Adjust eps as needed\n",
    "clusters = dbscan.fit_predict(coords_scaled)\n",
    "\n",
    "df_danger.loc[:, 'cluster'] = clusters  # Adding cluster labels to DataFrame\n",
    "\n",
    "\n",
    "df_danger_cluster = df_danger[df_danger['cluster'] > -1]\n",
    "\n",
    "\n",
    "# %matplotlib inline\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df_danger_cluster['lng'], df_danger_cluster['lat'], c=df_danger_cluster['cluster'], cmap='tab10', edgecolors='k', alpha=0.7)\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('DBSCAN Clustering of Geospatial Data')\n",
    "plt.colorbar(label='Cluster')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:18.984524Z",
     "start_time": "2025-02-01T18:48:18.979522Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['vehicleId', 'lat', 'lng', 'dateStored', 'velocity', 'odometer',\n",
       "       'engineVoltage', 'dateStoredHuman', 'dateOnlyStoredHuman', 'timeOnly',\n",
       "       'orientation', 'seconds_diff', 'acceleration', 'isProblem', 'cluster'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_danger.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Showing convex hulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:21.258667Z",
     "start_time": "2025-02-01T18:48:21.249980Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:21.832752Z",
     "start_time": "2025-02-01T18:48:21.685594Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_71284/2620042853.py:5: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  colors = plt.cm.get_cmap(\"tab10\", len(unique_clusters))  # Set of distinct colors for clusters\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unable to determine Axes to steal space for Colorbar. Either provide the *cax* argument to use as the Axes for the Colorbar, provide the *ax* argument to steal space from it, or add *mappable* to an Axes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 38\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m#plt.legend()\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 38\u001b[0m \u001b[43mplot_convex_hulls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_danger_cluster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclusters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43misProblem\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 31\u001b[0m, in \u001b[0;36mplot_convex_hulls\u001b[0;34m(df, clusters, normal_df_points)\u001b[0m\n\u001b[1;32m     28\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDBSCAN Clustering of Geospatial Data with Convex Hulls\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Create colorbar using scatter points\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolorbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mScalarMappable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtab10\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43munique_clusters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43munique_clusters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m             \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCluster\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#plt.legend()\u001b[39;00m\n\u001b[1;32m     35\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/anaconda3/envs/ArcGIS/lib/python3.9/site-packages/matplotlib/pyplot.py:2516\u001b[0m, in \u001b[0;36mcolorbar\u001b[0;34m(mappable, cax, ax, **kwargs)\u001b[0m\n\u001b[1;32m   2511\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mappable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2512\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo mappable was found to use for colorbar \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2513\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreation. First define a mappable such as \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2514\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124man image (with imshow) or a contour set (\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2515\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwith contourf).\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 2516\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mgcf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolorbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmappable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2517\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/anaconda3/envs/ArcGIS/lib/python3.9/site-packages/matplotlib/figure.py:1215\u001b[0m, in \u001b[0;36mFigureBase.colorbar\u001b[0;34m(self, mappable, cax, ax, use_gridspec, **kwargs)\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1215\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1216\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnable to determine Axes to steal space for Colorbar. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1217\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEither provide the *cax* argument to use as the Axes for \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1218\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe Colorbar, provide the *ax* argument to steal space \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1219\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrom it, or add *mappable* to an Axes.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1220\u001b[0m     fig \u001b[38;5;241m=\u001b[39m (  \u001b[38;5;66;03m# Figure of first Axes; logic copied from make_axes.\u001b[39;00m\n\u001b[1;32m   1221\u001b[0m         [\u001b[38;5;241m*\u001b[39max\u001b[38;5;241m.\u001b[39mflat] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ax, np\u001b[38;5;241m.\u001b[39mndarray)\n\u001b[1;32m   1222\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;241m*\u001b[39max] \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39miterable(ax)\n\u001b[1;32m   1223\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m [ax])[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mfigure\n\u001b[1;32m   1224\u001b[0m     current_ax \u001b[38;5;241m=\u001b[39m fig\u001b[38;5;241m.\u001b[39mgca()\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to determine Axes to steal space for Colorbar. Either provide the *cax* argument to use as the Axes for the Colorbar, provide the *ax* argument to steal space from it, or add *mappable* to an Axes."
     ]
    }
   ],
   "source": [
    "def plot_convex_hulls(df, clusters, normal_df_points):\n",
    "    # %matplotlib qt\n",
    "\n",
    "    unique_clusters = set(clusters)\n",
    "    colors = plt.cm.get_cmap(\"tab10\", len(unique_clusters))  # Set of distinct colors for clusters\n",
    "\n",
    "    # Plot points first for colorbar\n",
    "    for cluster in unique_clusters:\n",
    "        if cluster == -1:\n",
    "            continue  # Skip noise points\n",
    "        cluster_points = df[df['cluster'] == cluster][['lng', 'lat']].values\n",
    "        plt.scatter(cluster_points[:, 0], cluster_points[:, 1], label=f'Cluster {cluster}', c=[colors(cluster)], s=10)\n",
    "\n",
    "    plt.scatter(normal_df_points['lng'], normal_df_points['lat'], c='gray', alpha=0.5)\n",
    "\n",
    "    # Plot Convex Hulls\n",
    "    for cluster in unique_clusters:\n",
    "        if cluster == -1:\n",
    "            continue  # Skip noise points\n",
    "        cluster_points = df[df['cluster'] == cluster][['lng', 'lat']].values\n",
    "        if len(cluster_points) >= 3:  # Convex hull requires at least 3 points\n",
    "            hull = ConvexHull(cluster_points)\n",
    "            hull_points = np.append(hull.vertices, hull.vertices[0])  # Close the loop\n",
    "            plt.plot(cluster_points[hull_points, 0], cluster_points[hull_points, 1], 'r-')\n",
    "\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.title('DBSCAN Clustering of Geospatial Data with Convex Hulls')\n",
    "\n",
    "    # Create colorbar using scatter points\n",
    "    plt.colorbar(plt.cm.ScalarMappable(cmap=\"tab10\", norm=plt.Normalize(vmin=min(unique_clusters), vmax=max(unique_clusters))),\n",
    "                 label='Cluster')\n",
    "\n",
    "    #plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_convex_hulls(df_danger_cluster, clusters, df[df['isProblem'] == 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:28.027793Z",
     "start_time": "2025-02-01T18:48:27.999452Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest Cluster: 0\n",
      "Bounding Box: {'min_lng': 23.7323533, 'min_lat': 38.0112216, 'max_lng': 23.7928033, 'max_lat': 38.0534233}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import ConvexHull\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "def get_largest_cluster_bounding_box(df, cluster_column='cluster', coord_columns=['lng', 'lat']):\n",
    "    # Get unique clusters\n",
    "    unique_clusters = df[cluster_column].unique()\n",
    "\n",
    "    largest_area = 0\n",
    "    largest_cluster = None\n",
    "    largest_hull_points = None\n",
    "\n",
    "    # Iterate through clusters to find the one with the largest area\n",
    "    for cluster in unique_clusters:\n",
    "        if cluster == -1:  # Skip noise points\n",
    "            continue\n",
    "\n",
    "        # Get the points for the current cluster\n",
    "        cluster_points = df[df[cluster_column] == cluster][coord_columns].values\n",
    "\n",
    "        # Compute the convex hull\n",
    "        if len(cluster_points) >= 3:  # Convex hull requires at least 3 points\n",
    "            hull = ConvexHull(cluster_points)\n",
    "            hull_points = cluster_points[hull.vertices]\n",
    "            hull_area = hull.volume  # For 2D, 'volume' is the area of the convex hull\n",
    "\n",
    "            if hull_area > largest_area:\n",
    "                largest_area = hull_area\n",
    "                largest_cluster = cluster\n",
    "                largest_hull_points = hull_points\n",
    "\n",
    "    # If no clusters found or all were noise, return None\n",
    "    if largest_cluster is None:\n",
    "        return None\n",
    "\n",
    "    # Create a Polygon object from the convex hull\n",
    "    polygon = Polygon(largest_hull_points)\n",
    "\n",
    "    # Get the bounding box (min and max lat, lng)\n",
    "    min_lng, min_lat, max_lng, max_lat = polygon.bounds\n",
    "\n",
    "    return {\n",
    "        'largest_cluster': largest_cluster,\n",
    "        'bounding_box': {\n",
    "            'min_lng': min_lng,\n",
    "            'min_lat': min_lat,\n",
    "            'max_lng': max_lng,\n",
    "            'max_lat': max_lat\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Example usage:\n",
    "# Assuming df_danger is the DataFrame with the 'cluster' column, 'lng', and 'lat'\n",
    "result = get_largest_cluster_bounding_box(df_danger)\n",
    "if result:\n",
    "    print(f\"Largest Cluster: {result['largest_cluster']}\")\n",
    "    print(f\"Bounding Box: {result['bounding_box']}\")\n",
    "else:\n",
    "    print(\"No valid clusters found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:29.200017Z",
     "start_time": "2025-02-01T18:48:29.191447Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:29.390169Z",
     "start_time": "2025-02-01T18:48:29.385043Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:29.581721Z",
     "start_time": "2025-02-01T18:48:29.577151Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:29.755180Z",
     "start_time": "2025-02-01T18:48:29.750637Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:29.911737Z",
     "start_time": "2025-02-01T18:48:29.907023Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:30.106270Z",
     "start_time": "2025-02-01T18:48:30.101129Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:30.279920Z",
     "start_time": "2025-02-01T18:48:30.275006Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:30.464254Z",
     "start_time": "2025-02-01T18:48:30.459088Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:30.648854Z",
     "start_time": "2025-02-01T18:48:30.643996Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T16:51:59.915882Z",
     "start_time": "2025-02-01T16:51:41.908673Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt# Collect coords into list\n",
    "import requests\n",
    "\n",
    "import json\n",
    "overpass_url = \"http://overpass-api.de/api/interpreter\"\n",
    "overpass_query = \"\"\"\n",
    "[out:json];\n",
    "area[\"ISO3166-1\"=\"DE\"][admin_level=2];\n",
    "(node[\"amenity\"=\"biergarten\"](area);\n",
    " way[\"amenity\"=\"biergarten\"](area);\n",
    " rel[\"amenity\"=\"biergarten\"](area);\n",
    ");\n",
    "out center;\n",
    "\"\"\"\n",
    "response = requests.get(overpass_url,\n",
    "                        params={'data': overpass_query})\n",
    "data = response.json()\n",
    "\n",
    "coords = []\n",
    "for element in data['elements']:\n",
    "    if element['type'] == 'node':\n",
    "        lon = element['lon']\n",
    "        lat = element['lat']\n",
    "        coords.append((lon, lat))\n",
    "    elif 'center' in element:\n",
    "        lon = element['center']['lon']\n",
    "        lat = element['center']['lat']\n",
    "        coords.append((lon, lat))# Convert coordinates into numpy array\n",
    "\n",
    "\n",
    "X = np.array(coords)\n",
    "\n",
    "plt.plot(X[:, 0], X[:, 1], 'o')\n",
    "plt.title('Biergarten in Germany')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T16:57:45.289285Z",
     "start_time": "2025-02-01T16:57:15.624007Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "# Define bounding box (min_lon, min_lat, max_lon, max_lat)\n",
    "bbox = (-122.523, 37.704, -122.354, 37.833)  # Example: San Francisco\n",
    "\n",
    "# Example coordinate points (replace with real data)\n",
    "coords = [\n",
    "    (-122.45, 37.75),\n",
    "    (-122.40, 37.78),\n",
    "    (-122.48, 37.73)\n",
    "]\n",
    "\n",
    "# Convert to numpy array\n",
    "X = np.array(coords)\n",
    "\n",
    "# Create a figure with Cartopy\n",
    "fig, ax = plt.subplots(figsize=(6, 4), subplot_kw={\"projection\": ccrs.PlateCarree()})\n",
    "\n",
    "# Set the map extent to the bounding box\n",
    "ax.set_extent([bbox[0], bbox[2], bbox[1], bbox[3]], crs=ccrs.PlateCarree())\n",
    "\n",
    "# Add roads and features\n",
    "ax.add_feature(cfeature.LAND, color=\"lightgray\")\n",
    "ax.add_feature(cfeature.OCEAN, color=\"lightblue\")\n",
    "ax.add_feature(cfeature.BORDERS, linestyle=\":\")\n",
    "ax.add_feature(cfeature.COASTLINE)\n",
    "ax.add_feature(cfeature.LAKES, color=\"blue\", alpha=0.3)\n",
    "ax.add_feature(cfeature.RIVERS, color=\"blue\", alpha=0.3)\n",
    "\n",
    "# Plot points\n",
    "ax.scatter(X[:, 0], X[:, 1], color=\"red\", marker=\"o\", label=\"Points\")\n",
    "\n",
    "# Labels and title\n",
    "ax.set_title(\"Custom Location Map\")\n",
    "ax.legend()\n",
    "\n",
    "# Save the output\n",
    "output_filename = \"local_map.png\"\n",
    "plt.savefig(output_filename, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Map with points saved as {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGIS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
