{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:02.444705Z",
     "start_time": "2025-02-01T18:48:02.442519Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.neighbors import KernelDensity, BallTree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial import ConvexHull\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import os\n",
    "from colorama import Fore, Style\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import ConvexHull\n",
    "from shapely.geometry import Polygon\n",
    "import json\n",
    "import plotly.express as px\n",
    "from haversine import haversine, Unit\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# File loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:02.670714Z",
     "start_time": "2025-02-01T18:48:02.667030Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"vehicleId\", \n",
    "    \"lat\", \n",
    "    \"lng\", \n",
    "    # \"dateStored\", \n",
    "    \"velocity\",\n",
    "    # \"odometer\", \n",
    "    # \"engineVoltage\", \n",
    "    \"dateStoredHuman\", \n",
    "    # \"dateOnlyStoredHuman\",    \n",
    "    # \"timeOnly\",\n",
    "    \"bearing\",\n",
    "    \"orientation\", \n",
    "    \"bearing_diff\",\n",
    "    \"seconds_diff\", \n",
    "    \"acceleration\",\n",
    "    \"isProblem\",\n",
    "    \"trip_id\",\n",
    "    \"velocity_diff\",\n",
    "    \"distance_m\"\n",
    "]\n",
    "\n",
    "\n",
    "input_dir   = \"../../DataSets/API_Responses/Vehicle_Data/\"\n",
    "filename    = \"all_vehicle_responses.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable matloblib UI backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save plots file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_FOLDER_PATH = \"./Plots/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:03.383127Z",
     "start_time": "2025-02-01T18:48:03.325978Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   vehicleId        lat        lng  velocity      dateStoredHuman  distance_m  \\\n",
      "0          1  37.510833  22.385710       0.0  2024-06-06 17:02:17        0.00   \n",
      "1          1  37.510603  22.385977       0.0  2024-06-06 17:02:20       34.75   \n",
      "2          1  37.510640  22.385927       6.0  2024-06-06 17:02:25        6.01   \n",
      "3          1  37.510750  22.385907       7.0  2024-06-06 17:02:31       12.33   \n",
      "4          1  37.510877  22.385698      26.0  2024-06-06 17:02:37       23.17   \n",
      "\n",
      "   seconds_diff  trip_id     bearing orientation  bearing_diff  velocity_diff  \\\n",
      "0           0.0        0  137.402376   Southeast          0.00            0.0   \n",
      "1           3.0        0  312.778670   Northwest        175.38            0.0   \n",
      "2           5.0        0  351.785725       North         39.01            6.0   \n",
      "3           6.0        0  307.481149   Northwest         44.30            1.0   \n",
      "4           6.0        0  318.388767   Northwest         10.91           19.0   \n",
      "\n",
      "   acceleration  isProblem  \n",
      "0      0.000000          0  \n",
      "1      0.000000          0  \n",
      "2      0.333333          0  \n",
      "3      0.046296          0  \n",
      "4      0.879630          0  \n"
     ]
    }
   ],
   "source": [
    "def merge_csv_file(input_dir, filename, columns):\n",
    "    input_file = os.path.join(input_dir, filename)\n",
    "\n",
    "    if not os.path.exists(input_file):\n",
    "        raise FileNotFoundError(f\"File '{filename}' not found in directory '{input_dir}'\")\n",
    "\n",
    "    try:\n",
    "        # Read the CSV while allowing missing columns\n",
    "        df = pd.read_csv(input_file, usecols=lambda x: x.strip() in columns, encoding='utf-8')\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error reading '{input_file}': {e}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "merged_dfs = merge_csv_file(input_dir, filename, columns)\n",
    "print(merged_dfs.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set **Bounding Box** only for **Τρίπολη**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:12.258811Z",
     "start_time": "2025-02-01T18:48:12.187714Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Density of problem points on spatial coordinates')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = merged_dfs\n",
    "df_danger = df[df['isProblem'] == 1]\n",
    "# df_danger = df[df['vehicleId'] == 15]\n",
    "\n",
    "\n",
    "sns.set_theme(style=\"ticks\")\n",
    "fig, ax = plt.subplots()\n",
    "#sns.jointplot(x=df_danger['lng'], y=df_danger['lat'], kind=\"hex\", color=\"#4CB391\", ax=ax)\n",
    "ax.hexbin(x=df_danger['lng'], y=df_danger['lat'])\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "\n",
    "plt.gca().xaxis.set_major_formatter(ScalarFormatter())\n",
    "plt.gca().yaxis.set_major_formatter(ScalarFormatter())\n",
    "plt.ticklabel_format(style='plain', axis='both')  # Disable scientific notation\n",
    "\n",
    "\n",
    "ax.set_title('Density of problem points on spatial coordinates')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init DF15 (VehicleId == 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df15 = df[df[\"vehicleId\"] == 15]\n",
    "# df15 = df15.head(500)\n",
    "# df15_problem = df15[df15['isProblem'] == 1]\n",
    "# plt.plot(df15.index, df15['acceleration'])\n",
    "# plt.title('Acceleration vs Index')\n",
    "# plt.ylabel('Acceleration')\n",
    "# plt.xlabel('Index')\n",
    "# plt.scatter(df15_problem.index, df15_problem['acceleration'], color='red')\n",
    "\n",
    "# len(df15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:12.613965Z",
     "start_time": "2025-02-01T18:48:12.598846Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lng</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2194.000000</td>\n",
       "      <td>2194.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>22.378132</td>\n",
       "      <td>37.515329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.006988</td>\n",
       "      <td>0.006203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>22.363152</td>\n",
       "      <td>37.497893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>22.372422</td>\n",
       "      <td>37.510810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>22.376219</td>\n",
       "      <td>37.513109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22.385158</td>\n",
       "      <td>37.519328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>22.415382</td>\n",
       "      <td>37.533140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               lng          lat\n",
       "count  2194.000000  2194.000000\n",
       "mean     22.378132    37.515329\n",
       "std       0.006988     0.006203\n",
       "min      22.363152    37.497893\n",
       "25%      22.372422    37.510810\n",
       "50%      22.376219    37.513109\n",
       "75%      22.385158    37.519328\n",
       "max      22.415382    37.533140"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_danger[['lng', 'lat']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:17.330420Z",
     "start_time": "2025-02-01T18:48:17.325963Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# #### MOCK DATA #####\n",
    "#\n",
    "# data = {\n",
    "#     'lng': np.random.uniform(-180, 180, 200),\n",
    "#     'lat': np.random.uniform(-90, 90, 200)\n",
    "# }\n",
    "# df = pd.DataFrame(data)\n",
    "# df_danger = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:17.808617Z",
     "start_time": "2025-02-01T18:48:17.802262Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:18.846543Z",
     "start_time": "2025-02-01T18:48:18.474283Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72020/1621334586.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_danger.loc[:, 'cluster'] = clusters  # Adding cluster labels to DataFrame\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to ./Plots/\n"
     ]
    }
   ],
   "source": [
    "# Extracting the coordinates\n",
    "coords = df_danger[['lng', 'lat']].values\n",
    "\n",
    "# Standardizing the data for better clustering performance\n",
    "scaler = StandardScaler()\n",
    "coords_scaled = scaler.fit_transform(coords)\n",
    "\n",
    "# Applying DBSCAN\n",
    "dbscan = DBSCAN(eps=0.02, min_samples=4)  # Adjust eps as needed\n",
    "clusters = dbscan.fit_predict(coords_scaled)\n",
    "\n",
    "df_danger.loc[:, 'cluster'] = clusters  # Adding cluster labels to DataFrame\n",
    "\n",
    "\n",
    "df_danger_cluster = df_danger[df_danger['cluster'] > -1]\n",
    "\n",
    "\n",
    "# %matplotlib inline\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df_danger_cluster['lng'], df_danger_cluster['lat'], c=df_danger_cluster['cluster'], cmap='tab10', edgecolors='k', alpha=0.7)\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('DBSCAN Clustering of Geospatial Data')\n",
    "plt.colorbar(label='Cluster')\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(PLOT_FOLDER_PATH, bbox_inches='tight')\n",
    "print(f\"Plot saved to {PLOT_FOLDER_PATH}\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:18.984524Z",
     "start_time": "2025-02-01T18:48:18.979522Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['vehicleId', 'lat', 'lng', 'velocity', 'dateStoredHuman', 'distance_m',\n",
       "       'seconds_diff', 'trip_id', 'bearing', 'orientation', 'bearing_diff',\n",
       "       'velocity_diff', 'acceleration', 'isProblem', 'cluster'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_danger.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vehicleId</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>velocity</th>\n",
       "      <th>distance_m</th>\n",
       "      <th>seconds_diff</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>bearing</th>\n",
       "      <th>bearing_diff</th>\n",
       "      <th>velocity_diff</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>isProblem</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2194.000000</td>\n",
       "      <td>2194.000000</td>\n",
       "      <td>2194.000000</td>\n",
       "      <td>2194.000000</td>\n",
       "      <td>2194.00000</td>\n",
       "      <td>2194.000000</td>\n",
       "      <td>2194.000000</td>\n",
       "      <td>2194.000000</td>\n",
       "      <td>2194.000000</td>\n",
       "      <td>2194.000000</td>\n",
       "      <td>2194.000000</td>\n",
       "      <td>2194.0</td>\n",
       "      <td>2194.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.559708</td>\n",
       "      <td>37.515329</td>\n",
       "      <td>22.378132</td>\n",
       "      <td>14.578851</td>\n",
       "      <td>18.80577</td>\n",
       "      <td>3.530994</td>\n",
       "      <td>143.736554</td>\n",
       "      <td>181.834256</td>\n",
       "      <td>73.738127</td>\n",
       "      <td>-11.404284</td>\n",
       "      <td>-1.070413</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.009116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.078162</td>\n",
       "      <td>0.006203</td>\n",
       "      <td>0.006988</td>\n",
       "      <td>14.990388</td>\n",
       "      <td>29.26726</td>\n",
       "      <td>3.172815</td>\n",
       "      <td>144.158906</td>\n",
       "      <td>107.172766</td>\n",
       "      <td>91.240364</td>\n",
       "      <td>9.917360</td>\n",
       "      <td>1.123217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.368397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.497893</td>\n",
       "      <td>22.363152</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-141.000000</td>\n",
       "      <td>-14.722222</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>37.510810</td>\n",
       "      <td>22.372422</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.79250</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>93.838222</td>\n",
       "      <td>10.262500</td>\n",
       "      <td>-14.000000</td>\n",
       "      <td>-1.111111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>37.513109</td>\n",
       "      <td>22.376219</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>15.21000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>186.731220</td>\n",
       "      <td>33.035000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>-0.763889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>37.519328</td>\n",
       "      <td>22.385158</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>22.75750</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>276.508284</td>\n",
       "      <td>102.567500</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-0.555556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>37.533140</td>\n",
       "      <td>22.415382</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>579.01000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>505.000000</td>\n",
       "      <td>359.405846</td>\n",
       "      <td>358.230000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-0.505051</td>\n",
       "      <td>1.0</td>\n",
       "      <td>61.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         vehicleId          lat          lng     velocity  distance_m  \\\n",
       "count  2194.000000  2194.000000  2194.000000  2194.000000  2194.00000   \n",
       "mean      7.559708    37.515329    22.378132    14.578851    18.80577   \n",
       "std       4.078162     0.006203     0.006988    14.990388    29.26726   \n",
       "min       1.000000    37.497893    22.363152     0.000000     0.00000   \n",
       "25%       7.000000    37.510810    22.372422     6.000000     6.79250   \n",
       "50%       7.000000    37.513109    22.376219    10.000000    15.21000   \n",
       "75%       9.000000    37.519328    22.385158    18.000000    22.75750   \n",
       "max      20.000000    37.533140    22.415382   123.000000   579.01000   \n",
       "\n",
       "       seconds_diff      trip_id      bearing  bearing_diff  velocity_diff  \\\n",
       "count   2194.000000  2194.000000  2194.000000   2194.000000    2194.000000   \n",
       "mean       3.530994   143.736554   181.834256     73.738127     -11.404284   \n",
       "std        3.172815   144.158906   107.172766     91.240364       9.917360   \n",
       "min        1.000000     0.000000     0.000000      0.000000    -141.000000   \n",
       "25%        2.000000    23.000000    93.838222     10.262500     -14.000000   \n",
       "50%        3.000000    90.000000   186.731220     33.035000      -9.000000   \n",
       "75%        5.000000   207.000000   276.508284    102.567500      -5.000000   \n",
       "max       50.000000   505.000000   359.405846    358.230000      -2.000000   \n",
       "\n",
       "       acceleration  isProblem      cluster  \n",
       "count   2194.000000     2194.0  2194.000000  \n",
       "mean      -1.070413        1.0     9.009116  \n",
       "std        1.123217        0.0    18.368397  \n",
       "min      -14.722222        1.0    -1.000000  \n",
       "25%       -1.111111        1.0    -1.000000  \n",
       "50%       -0.763889        1.0    -1.000000  \n",
       "75%       -0.555556        1.0     9.000000  \n",
       "max       -0.505051        1.0    61.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_danger.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Showing convex hulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:21.258667Z",
     "start_time": "2025-02-01T18:48:21.249980Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:21.832752Z",
     "start_time": "2025-02-01T18:48:21.685594Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72020/113842607.py:3: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  colors = plt.cm.get_cmap(\"tab10\", len(unique_clusters))  # Set of distinct colors for clusters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to ./Plots/\n"
     ]
    }
   ],
   "source": [
    "def plot_convex_hulls(df, clusters, normal_df_points):\n",
    "    unique_clusters = set(clusters)\n",
    "    colors = plt.cm.get_cmap(\"tab10\", len(unique_clusters))  # Set of distinct colors for clusters\n",
    "\n",
    "    fig, ax = plt.subplots()  # Create figure and axis objects\n",
    "\n",
    "    # Plot points first for colorbar\n",
    "    for cluster in unique_clusters:\n",
    "        if cluster == -1:\n",
    "            continue  # Skip noise points\n",
    "        cluster_points = df[df['cluster'] == cluster][['lng', 'lat']].values\n",
    "        ax.scatter(cluster_points[:, 0], cluster_points[:, 1], label=f'Cluster {cluster}', c=[colors(cluster)], s=10)\n",
    "\n",
    "    ax.scatter(normal_df_points['lng'], normal_df_points['lat'], c='gray', alpha=0.5)\n",
    "\n",
    "    # Plot Convex Hulls\n",
    "    for cluster in unique_clusters:\n",
    "        if cluster == -1:\n",
    "            continue  # Skip noise points\n",
    "        cluster_points = df[df['cluster'] == cluster][['lng', 'lat']].values\n",
    "        if len(cluster_points) >= 3:  # Convex hull requires at least 3 points\n",
    "            hull = ConvexHull(cluster_points)\n",
    "            hull_points = np.append(hull.vertices, hull.vertices[0])  # Close the loop\n",
    "            ax.plot(cluster_points[hull_points, 0], cluster_points[hull_points, 1], 'r-')\n",
    "\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    ax.set_title('DBSCAN Clustering of Geospatial Data with Convex Hulls')\n",
    "\n",
    "    # Create colorbar using scatter points\n",
    "    cb = fig.colorbar(plt.cm.ScalarMappable(cmap=\"tab10\", norm=plt.Normalize(vmin=min(unique_clusters), vmax=max(unique_clusters))),\n",
    "                      ax=ax, label='Cluster')\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig(PLOT_FOLDER_PATH, bbox_inches='tight')\n",
    "    print(f\"Plot saved to {PLOT_FOLDER_PATH}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_convex_hulls(df_danger_cluster, clusters, df[df['isProblem'] == 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get specific **Cluster's BBOX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: {'min_lng': 22.3853133, 'max_lng': 22.3874666, 'min_lat': 37.5102916, 'max_lat': 37.5114683}\n",
      "Cluster 1: {'min_lng': 22.3841633, 'max_lng': 22.3843916, 'min_lat': 37.510425, 'max_lat': 37.5105433}\n",
      "Cluster 2: {'min_lng': 22.3848866, 'max_lng': 22.3851333, 'min_lat': 37.5107683, 'max_lat': 37.5109899}\n",
      "Cluster 3: {'min_lng': 22.3844933, 'max_lng': 22.3848033, 'min_lat': 37.510815, 'max_lat': 37.5110133}\n",
      "Cluster 4: {'min_lng': 22.3854, 'max_lng': 22.3854449, 'min_lat': 37.5114433, 'max_lat': 37.5117283}\n",
      "Cluster 5: {'min_lng': 22.3832566, 'max_lng': 22.3834216, 'min_lat': 37.5120583, 'max_lat': 37.512245}\n",
      "Cluster 6: {'min_lng': 22.3759916, 'max_lng': 22.3763466, 'min_lat': 37.512855, 'max_lat': 37.5131816}\n",
      "Cluster 7: {'min_lng': 22.3749533, 'max_lng': 22.3750599, 'min_lat': 37.509825, 'max_lat': 37.509945}\n",
      "Cluster 8: {'min_lng': 22.3840833, 'max_lng': 22.3842783, 'min_lat': 37.5138016, 'max_lat': 37.5138783}\n",
      "Cluster 9: {'min_lng': 22.3715183, 'max_lng': 22.3726783, 'min_lat': 37.5267833, 'max_lat': 37.5274349}\n",
      "Cluster 10: {'min_lng': 22.3720699, 'max_lng': 22.3725516, 'min_lat': 37.5218533, 'max_lat': 37.5221616}\n",
      "Cluster 11: {'min_lng': 22.372835, 'max_lng': 22.3731166, 'min_lat': 37.5289633, 'max_lat': 37.5291799}\n",
      "Cluster 12: {'min_lng': 22.3719916, 'max_lng': 22.3721733, 'min_lat': 37.52493, 'max_lat': 37.5250666}\n",
      "Cluster 13: {'min_lng': 22.3695883, 'max_lng': 22.3697833, 'min_lat': 37.5115, 'max_lat': 37.51166}\n",
      "Cluster 14: {'min_lng': 22.3745449, 'max_lng': 22.3747466, 'min_lat': 37.509585, 'max_lat': 37.5098233}\n",
      "Cluster 15: {'min_lng': 22.3672633, 'max_lng': 22.36759, 'min_lat': 37.5141383, 'max_lat': 37.5143366}\n",
      "Cluster 16: {'min_lng': 22.3735466, 'max_lng': 22.3737316, 'min_lat': 37.5082666, 'max_lat': 37.5085399}\n",
      "Cluster 17: {'min_lng': 22.379535, 'max_lng': 22.3796816, 'min_lat': 37.5212666, 'max_lat': 37.5213983}\n",
      "Cluster 18: {'min_lng': 22.3806366, 'max_lng': 22.3808183, 'min_lat': 37.5209833, 'max_lat': 37.5210983}\n",
      "Cluster 19: {'min_lng': 22.3732616, 'max_lng': 22.3737316, 'min_lat': 37.5111483, 'max_lat': 37.51154}\n",
      "Cluster 20: {'min_lng': 22.372555, 'max_lng': 22.3727066, 'min_lat': 37.521425, 'max_lat': 37.5216549}\n",
      "Cluster 21: {'min_lng': 22.3731849, 'max_lng': 22.37339, 'min_lat': 37.5114183, 'max_lat': 37.5115433}\n",
      "Cluster 22: {'min_lng': 22.37289, 'max_lng': 22.3729916, 'min_lat': 37.51149, 'max_lat': 37.511555}\n",
      "Cluster 23: {'min_lng': 22.3709299, 'max_lng': 22.3710433, 'min_lat': 37.5186449, 'max_lat': 37.5186983}\n",
      "Cluster 24: {'min_lng': 22.3739116, 'max_lng': 22.37446, 'min_lat': 37.5130683, 'max_lat': 37.5134366}\n",
      "Cluster 25: {'min_lng': 22.3749533, 'max_lng': 22.375, 'min_lat': 37.5151933, 'max_lat': 37.5153133}\n",
      "Cluster 26: {'min_lng': 22.3706266, 'max_lng': 22.37069, 'min_lat': 37.5293883, 'max_lat': 37.52946}\n",
      "Cluster 27: {'min_lng': 22.3744883, 'max_lng': 22.37585, 'min_lat': 37.5127133, 'max_lat': 37.5133983}\n",
      "Cluster 28: {'min_lng': 22.369125, 'max_lng': 22.3693816, 'min_lat': 37.5153816, 'max_lat': 37.5157916}\n",
      "Cluster 29: {'min_lng': 22.3729466, 'max_lng': 22.3733466, 'min_lat': 37.5208, 'max_lat': 37.5209883}\n",
      "Cluster 30: {'min_lng': 22.3742449, 'max_lng': 22.37433, 'min_lat': 37.5122616, 'max_lat': 37.5124533}\n",
      "Cluster 31: {'min_lng': 22.3754416, 'max_lng': 22.3755366, 'min_lat': 37.5129616, 'max_lat': 37.51309}\n",
      "Cluster 32: {'min_lng': 22.3789333, 'max_lng': 22.3792183, 'min_lat': 37.5222066, 'max_lat': 37.5222899}\n",
      "Cluster 33: {'min_lng': 22.3722683, 'max_lng': 22.372415, 'min_lat': 37.52261, 'max_lat': 37.52269}\n",
      "Cluster 34: {'min_lng': 22.3721666, 'max_lng': 22.3723683, 'min_lat': 37.5261566, 'max_lat': 37.5264249}\n",
      "Cluster 35: {'min_lng': 22.3724633, 'max_lng': 22.3725316, 'min_lat': 37.5223083, 'max_lat': 37.5223533}\n",
      "Cluster 36: {'min_lng': 22.3697533, 'max_lng': 22.3699449, 'min_lat': 37.5192666, 'max_lat': 37.5194466}\n",
      "Cluster 37: {'min_lng': 22.3713949, 'max_lng': 22.3716216, 'min_lat': 37.5267716, 'max_lat': 37.526845}\n",
      "Cluster 38: {'min_lng': 22.369485, 'max_lng': 22.3695266, 'min_lat': 37.5171533, 'max_lat': 37.5172833}\n",
      "Cluster 39: {'min_lng': 22.371305, 'max_lng': 22.371385, 'min_lat': 37.5125249, 'max_lat': 37.512655}\n",
      "Cluster 40: {'min_lng': 22.3720183, 'max_lng': 22.37217, 'min_lat': 37.5240233, 'max_lat': 37.5242083}\n",
      "Cluster 41: {'min_lng': 22.3728933, 'max_lng': 22.3730516, 'min_lat': 37.511175, 'max_lat': 37.5112699}\n",
      "Cluster 42: {'min_lng': 22.3763533, 'max_lng': 22.3765433, 'min_lat': 37.5128116, 'max_lat': 37.5129816}\n",
      "Cluster 43: {'min_lng': 22.3671416, 'max_lng': 22.367365, 'min_lat': 37.5143583, 'max_lat': 37.5145466}\n",
      "Cluster 44: {'min_lng': 22.3712583, 'max_lng': 22.3715249, 'min_lat': 37.5312116, 'max_lat': 37.5313683}\n",
      "Cluster 45: {'min_lng': 22.37789, 'max_lng': 22.3781666, 'min_lat': 37.5250533, 'max_lat': 37.5252999}\n",
      "Cluster 46: {'min_lng': 22.3707233, 'max_lng': 22.3710849, 'min_lat': 37.530565, 'max_lat': 37.53072}\n",
      "Cluster 47: {'min_lng': 22.3712416, 'max_lng': 22.3713666, 'min_lat': 37.5306583, 'max_lat': 37.5307449}\n",
      "Cluster 48: {'min_lng': 22.3822883, 'max_lng': 22.3824783, 'min_lat': 37.519085, 'max_lat': 37.5192216}\n",
      "Cluster 49: {'min_lng': 22.3815383, 'max_lng': 22.3817683, 'min_lat': 37.5182666, 'max_lat': 37.51846}\n",
      "Cluster 50: {'min_lng': 22.3792266, 'max_lng': 22.3797466, 'min_lat': 37.5100083, 'max_lat': 37.5109016}\n",
      "Cluster 51: {'min_lng': 22.378305, 'max_lng': 22.3783366, 'min_lat': 37.511505, 'max_lat': 37.511555}\n",
      "Cluster 52: {'min_lng': 22.37901, 'max_lng': 22.37926, 'min_lat': 37.5095333, 'max_lat': 37.5098316}\n",
      "Cluster 53: {'min_lng': 22.3805999, 'max_lng': 22.3808816, 'min_lat': 37.51096, 'max_lat': 37.5110449}\n",
      "Cluster 54: {'min_lng': 22.3784533, 'max_lng': 22.378655, 'min_lat': 37.5109666, 'max_lat': 37.511035}\n",
      "Cluster 55: {'min_lng': 22.381105, 'max_lng': 22.3812733, 'min_lat': 37.51169, 'max_lat': 37.5117383}\n",
      "Cluster 56: {'min_lng': 22.3840316, 'max_lng': 22.3842216, 'min_lat': 37.5147333, 'max_lat': 37.514995}\n",
      "Cluster 57: {'min_lng': 22.3703516, 'max_lng': 22.37055, 'min_lat': 37.5121266, 'max_lat': 37.5122749}\n",
      "Cluster 58: {'min_lng': 22.3879333, 'max_lng': 22.3886466, 'min_lat': 37.5148066, 'max_lat': 37.515735}\n",
      "Cluster 59: {'min_lng': 22.3797633, 'max_lng': 22.3801566, 'min_lat': 37.5110583, 'max_lat': 37.5114033}\n",
      "Cluster 60: {'min_lng': 22.38037, 'max_lng': 22.3805866, 'min_lat': 37.5205566, 'max_lat': 37.5206416}\n",
      "Cluster 61: {'min_lng': 22.3729316, 'max_lng': 22.373, 'min_lat': 37.5283533, 'max_lat': 37.5285433}\n"
     ]
    }
   ],
   "source": [
    "def get_bbox_of_clusters(df, clusters):\n",
    "    cluster_bboxes = {}\n",
    "\n",
    "    # Iterate over unique clusters (excluding -1 for noise)\n",
    "    unique_clusters = sorted(set(clusters) - {-1})  # Exclude noise points (-1)\n",
    "\n",
    "    for cluster in unique_clusters:\n",
    "        # Filter the points of the current cluster\n",
    "        cluster_points = df[df['cluster'] == cluster][['lng', 'lat']]\n",
    "        \n",
    "        # Get the minimum and maximum lng and lat for the bounding box\n",
    "        min_lng = cluster_points['lng'].min()\n",
    "        max_lng = cluster_points['lng'].max()\n",
    "        min_lat = cluster_points['lat'].min()\n",
    "        max_lat = cluster_points['lat'].max()\n",
    "\n",
    "        # Store the bounding box for the current cluster\n",
    "        cluster_bboxes[cluster] = {\n",
    "            'min_lng': min_lng,\n",
    "            'max_lng': max_lng,\n",
    "            'min_lat': min_lat,\n",
    "            'max_lat': max_lat\n",
    "        }\n",
    "\n",
    "    return cluster_bboxes\n",
    "\n",
    "cluster_bboxes = get_bbox_of_clusters(df_danger_cluster, clusters)\n",
    "\n",
    "# Display the bounding boxes for each cluster\n",
    "for cluster, bbox in cluster_bboxes.items():\n",
    "    print(f\"Cluster {cluster}: {bbox}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:29.200017Z",
     "start_time": "2025-02-01T18:48:29.191447Z"
    },
    "collapsed": false
   },
   "source": [
    "## Plot Orientations with Convex Hulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:29.581721Z",
     "start_time": "2025-02-01T18:48:29.577151Z"
    },
    "collapsed": false
   },
   "source": [
    "### Prepare the DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:29.755180Z",
     "start_time": "2025-02-01T18:48:29.750637Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       vehicleId        lat        lng      dateStoredHuman     bearing  \\\n",
      "0              1  37.510833  22.385710  2024-06-06 17:02:17  137.402376   \n",
      "1              1  37.510603  22.385977  2024-06-06 17:02:20  312.778670   \n",
      "2              1  37.510640  22.385927  2024-06-06 17:02:25  351.785725   \n",
      "3              1  37.510750  22.385907  2024-06-06 17:02:31  307.481149   \n",
      "4              1  37.510877  22.385698  2024-06-06 17:02:37  318.388767   \n",
      "...          ...        ...        ...                  ...         ...   \n",
      "28443         20  37.531460  22.369768  2025-03-06 13:09:13  231.663210   \n",
      "28444         20  37.531275  22.369473  2025-03-06 13:09:15  235.207818   \n",
      "28445         20  37.531122  22.369195  2025-03-06 13:09:19  278.389323   \n",
      "28446         20  37.531148  22.368967  2025-03-06 13:09:21  294.596339   \n",
      "28447         20  37.531243  22.368705  2025-03-06 13:09:24         NaN   \n",
      "\n",
      "      orientation  seconds_diff  trip_id  \n",
      "0       Southeast           0.0        0  \n",
      "1       Northwest           3.0        0  \n",
      "2           North           5.0        0  \n",
      "3       Northwest           6.0        0  \n",
      "4       Northwest           6.0        0  \n",
      "...           ...           ...      ...  \n",
      "28443   Southwest           4.0       11  \n",
      "28444   Southwest           2.0       11  \n",
      "28445        West           4.0       11  \n",
      "28446   Northwest           2.0       11  \n",
      "28447         NaN           3.0       11  \n",
      "\n",
      "[28448 rows x 8 columns]\n",
      "The trip_id with the most rows for vehicleId 1 is: 64\n"
     ]
    }
   ],
   "source": [
    "# *Get specific columns \n",
    "_ = merged_dfs.copy()\n",
    "bearings_df = _[['vehicleId', 'lat', 'lng', 'dateStoredHuman' ,'bearing', 'orientation', 'seconds_diff', 'trip_id']]\n",
    "print(bearings_df)\n",
    "\n",
    "# Filter for vehicleId == 1\n",
    "df_vehicle1 = df[df['vehicleId'] == 1]\n",
    "\n",
    "# Count occurrences of each trip_id\n",
    "trip_counts = df_vehicle1['trip_id'].value_counts()\n",
    "\n",
    "# Get the trip_id with the highest count\n",
    "most_frequent_trip_id = trip_counts.idxmax()\n",
    "\n",
    "# Display the result\n",
    "print(f\"The trip_id with the most rows for vehicleId 1 is: {most_frequent_trip_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get trip_id's rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:29.911737Z",
     "start_time": "2025-02-01T18:48:29.907023Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     vehicleId        lat        lng  velocity      dateStoredHuman  \\\n",
      "946          1  37.510722  22.387033      16.0  2024-06-08 17:32:23   \n",
      "947          1  37.510692  22.387185       8.0  2024-06-08 17:32:30   \n",
      "948          1  37.510670  22.387042       9.0  2024-06-08 17:32:38   \n",
      "949          1  37.510645  22.386773      22.0  2024-06-08 17:32:41   \n",
      "950          1  37.510685  22.386552      34.0  2024-06-08 17:32:43   \n",
      "\n",
      "     distance_m  seconds_diff  trip_id     bearing orientation  bearing_diff  \\\n",
      "946        0.00           0.0       64  103.998723        East          0.00   \n",
      "947       13.82           7.0       64  259.248208        West        155.25   \n",
      "948       12.90           8.0       64  263.300439        West          4.05   \n",
      "949       23.88           3.0       64  282.783117        West         19.48   \n",
      "950       20.10           2.0       64  277.535628        West          5.25   \n",
      "\n",
      "     velocity_diff  acceleration  isProblem  \n",
      "946          -40.0      0.000000          0  \n",
      "947           -8.0     -0.317460          0  \n",
      "948            1.0      0.034722          0  \n",
      "949           13.0      1.203704          0  \n",
      "950           12.0      1.666667          0  \n"
     ]
    }
   ],
   "source": [
    "print(df[(df['vehicleId'] == 1) & (df['trip_id'] == most_frequent_trip_id)].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot std deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2️⃣ Violin Plot (Distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:30.464254Z",
     "start_time": "2025-02-01T18:48:30.459088Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to ./Plots/\n"
     ]
    }
   ],
   "source": [
    "# Ensure std_dev is calculated\n",
    "std_dev = merged_dfs['bearing_diff'].std()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Create the violin plot\n",
    "sns.violinplot(x=merged_dfs['bearing_diff'], inner=\"quartile\", color=\"lightblue\")\n",
    "\n",
    "# Mark the standard deviation with a vertical line\n",
    "plt.axvline(x=std_dev, color='red', linestyle='--', label=f'Standard Deviation ({std_dev:.2f})')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Bearing Difference')\n",
    "plt.title('Violin Plot: Distribution of Bearing Difference')\n",
    "\n",
    "# Show legend\n",
    "plt.legend()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(PLOT_FOLDER_PATH, bbox_inches='tight')\n",
    "print(f\"Plot saved to {PLOT_FOLDER_PATH}\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print((merged_dfs['bearing_diff'] < 0).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:30.648854Z",
     "start_time": "2025-02-01T18:48:30.643996Z"
    },
    "collapsed": false
   },
   "source": [
    "### 3️⃣ Boxplot (Detect Outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to ./Plots/\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "sns.boxplot(x=merged_dfs['bearing_diff'], color='lightblue')\n",
    "\n",
    "# Mark the standard deviation\n",
    "plt.axvline(x=std_dev, color='red', linestyle='--', label=f'Standard Deviation ({std_dev:.2f})')\n",
    "\n",
    "plt.xlabel('Bearing Difference')\n",
    "plt.title('Boxplot: Bearing Difference Outliers')\n",
    "plt.legend()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(PLOT_FOLDER_PATH, bbox_inches='tight')\n",
    "print(f\"Plot saved to {PLOT_FOLDER_PATH}\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot bearings vs seconds diff "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ✅ Option 1: Matplotlib (simple, static plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(merged_dfs['seconds_diff'], merged_dfs['bearing_diff'], alpha=0.6, edgecolors='w')\n",
    "plt.title('Scatter Plot of Bearing Difference vs. Seconds Difference')\n",
    "plt.xlabel('Seconds Difference')\n",
    "plt.ylabel('Bering Difference')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plot_save_path = os.path.join(PLOT_FOLDER_PATH, \"Scatter_bearings_vs_seconds_diff.png\")\n",
    "plt.savefig(plot_save_path, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot bearings vs 10 seconds_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_72020/3279668019.py:17: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  colors = plt.cm.get_cmap('tab20', 20)  # Using the 'tab20' colormap\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame and take only the first 20 rows\n",
    "filtered_df = merged_dfs[merged_dfs['seconds_diff'] <= 10].head(20)\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Scatter plot (swapped axes)\n",
    "ax.scatter(\n",
    "    filtered_df['bearing_diff'],\n",
    "    filtered_df['seconds_diff'],\n",
    "    alpha=0.6,\n",
    "    edgecolors='w',\n",
    "    label='Points'\n",
    ")\n",
    "\n",
    "# Generate a list of 20 distinct colors using a colormap\n",
    "colors = plt.cm.get_cmap('tab20', 20)  # Using the 'tab20' colormap\n",
    "\n",
    "# Plot segments with changing color for each segment\n",
    "for i in range(len(filtered_df) - 1):\n",
    "    # Get the x and y values for the two points\n",
    "    x_start = filtered_df['bearing_diff'].iloc[i]\n",
    "    y_start = filtered_df['seconds_diff'].iloc[i]\n",
    "    x_end = filtered_df['bearing_diff'].iloc[i + 1]\n",
    "    y_end = filtered_df['seconds_diff'].iloc[i + 1]\n",
    "\n",
    "    # Assign a unique color for each segment from the 'tab20' colormap\n",
    "    color = colors(i)  # Get a different color for each segment\n",
    "\n",
    "    # Plot each segment with its own color\n",
    "    ax.plot([x_start, x_end], [y_start, y_end], color=color, lw=2)\n",
    "\n",
    "# Add incremental labels\n",
    "for i, (x, y) in enumerate(zip(filtered_df['bearing_diff'], filtered_df['seconds_diff'])):\n",
    "    ax.text(x + 0.5, y + 0.1, str(i), fontsize=9, color='black')\n",
    "\n",
    "# Prepare the orientation labels\n",
    "orientation_list = [f\"{i+1}. {orientation}\" for i, orientation in enumerate(filtered_df['orientation'])]\n",
    "\n",
    "# Prepare cell text for the table\n",
    "cell_text = [[orientation] for orientation in orientation_list]\n",
    "\n",
    "# Add the table on the right side of the plot (without color)\n",
    "table = ax.table(cellText=cell_text,\n",
    "                 colLabels=['Orientation'],\n",
    "                 loc='right',\n",
    "                 cellLoc='center',\n",
    "                 colColours=['lightgray'],  # Keep the header background color if desired\n",
    "                 bbox=[1.05, 0, 0.2, 1])  # Adjust bbox for position and size\n",
    "\n",
    "# Labels and title\n",
    "ax.set_title('Bearing Difference vs Seconds Difference (<= 10 seconds)')\n",
    "ax.set_xlabel('Bearing Diff')\n",
    "ax.set_ylabel('Seconds Diff')\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plot_save_path = os.path.join(PLOT_FOLDER_PATH, \"bearings_vs_seconds_diff.png\")\n",
    "plt.savefig(plot_save_path, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trajectory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot random vehicle ids and trip_ids **exclude VehicleId: 1 because it has problematic data points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 - vehicleId: 7, trip_id: 109\n",
      "Iteration 2 - vehicleId: 7, trip_id: 362\n",
      "Iteration 3 - vehicleId: 7, trip_id: 201\n",
      "Iteration 4 - vehicleId: 9, trip_id: 467\n",
      "Iteration 5 - vehicleId: 7, trip_id: 67\n",
      "Iteration 6 - vehicleId: 7, trip_id: 225\n",
      "Iteration 7 - vehicleId: 9, trip_id: 43\n",
      "Iteration 8 - vehicleId: 1, trip_id: 96\n",
      "Iteration 9 - vehicleId: 9, trip_id: 215\n",
      "Iteration 10 - vehicleId: 13, trip_id: 0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def random_ID(df):\n",
    "    # Group by 'vehicleId' and 'trip_id' to get the count of rows per trip_id\n",
    "    trip_counts = df.groupby(['vehicleId', 'trip_id']).size().reset_index(name='count')\n",
    "\n",
    "    # Filter out the trip_ids where the count is less than 10\n",
    "    valid_trip_counts = trip_counts[trip_counts['count'] >= 10]\n",
    "    \n",
    "    # Randomly select a vehicleId and trip_id from the valid ones\n",
    "    selected_trip = valid_trip_counts.sample(1).iloc[0]\n",
    "    vehID = selected_trip['vehicleId']\n",
    "    tripID = selected_trip['trip_id']\n",
    "    \n",
    "    return vehID, tripID\n",
    "\n",
    "# Loop through 10 times\n",
    "for i in range(10):\n",
    "    # Get a random vehicleId and trip_id with at least 10 rows\n",
    "    vehicle_id, trip_id = random_ID(merged_dfs)\n",
    "    print(f'Iteration {i+1} - vehicleId: {vehicle_id}, trip_id: {trip_id}')\n",
    "\n",
    "    # Filter the dataframe based on the selected vehicleId and trip_id\n",
    "    filtered_df = merged_dfs[(merged_dfs['vehicleId'] == vehicle_id) & (merged_dfs['trip_id'] == trip_id)]\n",
    "\n",
    "    # Get the number of rows for the selected trip_id\n",
    "    num_rows = len(filtered_df)\n",
    "    \n",
    "    # Plot the coordinates on a scatter plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(filtered_df['lng'], filtered_df['lat'], c='blue', marker='o', label=f'Vehicle {vehicle_id} - Trip {trip_id}')\n",
    "    \n",
    "    # Update the title to include the number of rows\n",
    "    plt.title(f'Coordinates for Vehicle {vehicle_id} - Trip {trip_id} - {num_rows} Data Points')\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter trips for calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      vehicleId  trip_id  count\n",
      "0             1        0     13\n",
      "1             1        1      2\n",
      "2             1        2      6\n",
      "3             1        3      4\n",
      "4             1        4      1\n",
      "...         ...      ...    ...\n",
      "1422         20        7      3\n",
      "1423         20        8     89\n",
      "1424         20        9     11\n",
      "1425         20       10      7\n",
      "1426         20       11     10\n",
      "\n",
      "[1427 rows x 3 columns]\n",
      "      vehicleId  trip_id  total_distance_m\n",
      "0             1        0            291.50\n",
      "1             1        1              3.88\n",
      "2             1        2             99.97\n",
      "3             1        3             44.61\n",
      "4             1        4              0.00\n",
      "...         ...      ...               ...\n",
      "1422         20        7             21.63\n",
      "1423         20        8           1597.54\n",
      "1424         20        9            253.65\n",
      "1425         20       10             25.93\n",
      "1426         20       11            239.76\n",
      "\n",
      "[1427 rows x 3 columns]\n",
      "Row difference excluded: 28448 - 25043 = 3405\n"
     ]
    }
   ],
   "source": [
    "# !Ensure trip_id has at least 6 rows, otherwise, do not calculate any slaloms\n",
    "trip_counts = merged_dfs.groupby(['vehicleId', 'trip_id']).size().reset_index(name='count')\n",
    "print(trip_counts)\n",
    "\n",
    "trip_distances = merged_dfs.groupby(['vehicleId', 'trip_id'])['distance_m'].sum().reset_index(name='total_distance_m')\n",
    "print(trip_distances)\n",
    "\n",
    "# *Filter only those trip_ids with more than 10 rows distance traveled > 50\n",
    "valid_trips = trip_counts[(trip_counts['count'] > 10) & (trip_distances['total_distance_m'] > 50.00)]\n",
    "\n",
    "filtered_merged_dfs = merged_dfs.copy()\n",
    "filtered_merged_dfs = pd.merge(merged_dfs, valid_trips[['vehicleId', 'trip_id']], on=['vehicleId', 'trip_id'], how='inner')\n",
    "print(f\"Row difference excluded: {len(merged_dfs)} - {len(filtered_merged_dfs)} = {len(merged_dfs) - len(filtered_merged_dfs)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save DF to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mDataFrame stored to ./visualize_dangers.csv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "visualize_dangers_path = \"./visualize_dangers.csv\"\n",
    "merged_dfs.to_csv(visualize_dangers_path, index=False)\n",
    "print(Fore.GREEN + f\"DataFrame stored to {visualize_dangers_path}\" + Style.RESET_ALL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGIS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
