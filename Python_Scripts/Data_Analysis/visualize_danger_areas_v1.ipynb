{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:02.444705Z",
     "start_time": "2025-02-01T18:48:02.442519Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Standard Library Imports\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "# Third-Party Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# from Imports\n",
    "from colorama import Fore, Style\n",
    "from haversine import haversine, Unit\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "from scipy.spatial import ConvexHull\n",
    "from scipy.stats import circmean, circstd, gaussian_kde\n",
    "from shapely.geometry import Polygon\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.neighbors import BallTree, KernelDensity\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# File loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:02.670714Z",
     "start_time": "2025-02-01T18:48:02.667030Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"vehicleId\", \n",
    "    \"lat\", \n",
    "    \"lng\", \n",
    "    # \"dateStored\", \n",
    "    \"velocity\",\n",
    "    # \"odometer\", \n",
    "    # \"engineVoltage\", \n",
    "    \"dateStoredHuman\", \n",
    "    # \"dateOnlyStoredHuman\",    \n",
    "    # \"timeOnly\",\n",
    "    \"bearing\",\n",
    "    \"orientation\", \n",
    "    \"bearing_diff\",\n",
    "    \"seconds_diff\", \n",
    "    \"acceleration\",\n",
    "    \"isProblem\",\n",
    "    \"trip_id\",\n",
    "    \"velocity_diff\",\n",
    "    \"distance_m\"\n",
    "]\n",
    "\n",
    "\n",
    "input_dir   = \"../../DataSets/API_Responses/Vehicle_Data/\"\n",
    "filename    = \"all_vehicle_responses.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable matloblib UI backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save plots & GeoJSONs files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLOT_FOLDER_PATH    = \"./Plots/\"\n",
    "\n",
    "GEOJSON_FOLDER_PATH = \"../../DataSets/GeoJSON/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:03.383127Z",
     "start_time": "2025-02-01T18:48:03.325978Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   vehicleId        lat        lng  velocity      dateStoredHuman  \\\n",
      "0          1  37.510833  22.385710       0.0  2024-06-06 17:02:17   \n",
      "1          1  37.510603  22.385977       0.0  2024-06-06 17:02:20   \n",
      "2          1  37.510640  22.385927       6.0  2024-06-06 17:02:25   \n",
      "3          1  37.510750  22.385907       7.0  2024-06-06 17:02:31   \n",
      "4          1  37.510877  22.385698      26.0  2024-06-06 17:02:37   \n",
      "\n",
      "   seconds_diff  trip_id  distance_m     bearing orientation  bearing_diff  \\\n",
      "0           0.0        0        0.00  137.402376   Southeast          0.00   \n",
      "1           3.0        0       34.75  312.778670   Northwest        175.38   \n",
      "2           5.0        0        6.01  351.785725       North         39.01   \n",
      "3           6.0        0       12.33  307.481149   Northwest         44.30   \n",
      "4           6.0        0       23.17  318.388767   Northwest         10.91   \n",
      "\n",
      "   velocity_diff  acceleration  isProblem  \n",
      "0            0.0      0.000000          0  \n",
      "1            0.0      0.000000          0  \n",
      "2            6.0      0.333333          0  \n",
      "3            1.0      0.046296          0  \n",
      "4           19.0      0.879630          0  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Reads a CSV file from the specified directory and returns a DataFrame containing only the specified columns.\n",
    "\n",
    "Args:\n",
    "    input_dir (str): Directory where the CSV file is located.\n",
    "    filename (str): Name of the CSV file to read.\n",
    "    columns (list): List of column names to retain in the output DataFrame.\n",
    "\n",
    "Returns:\n",
    "    pd.DataFrame: DataFrame containing only the specified columns from the CSV file.\n",
    "\n",
    "Raises:\n",
    "    FileNotFoundError: If the specified file does not exist in the given directory.\n",
    "    ValueError: If an error occurs during reading or parsing the CSV file.\n",
    "\"\"\"\n",
    "\n",
    "def merge_csv_file(input_dir, filename, columns):\n",
    "    input_file = os.path.join(input_dir, filename)\n",
    "\n",
    "    if not os.path.exists(input_file):\n",
    "        raise FileNotFoundError(f\"File '{filename}' not found in directory '{input_dir}'\")\n",
    "\n",
    "    try:\n",
    "        # Read the CSV while allowing missing columns\n",
    "        df = pd.read_csv(input_file, usecols=lambda x: x.strip() in columns, encoding='utf-8')\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error reading '{input_file}': {e}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "merged_dfs = merge_csv_file(input_dir, filename, columns)\n",
    "print(merged_dfs.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set **Bounding Box** only for **Τρίπολη**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:12.258811Z",
     "start_time": "2025-02-01T18:48:12.187714Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Density of problem points on spatial coordinates')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Filters the dataset for a specific vehicle and problematic entries, then visualizes the spatial density of these points using a hexbin plot.\n",
    "\n",
    "Steps:\n",
    "    - Filters `merged_dfs` for rows where 'isProblem' equals 1.\n",
    "    - Further filters to include only records for vehicleId 15.\n",
    "    - Plots a hexbin density map of longitude vs. latitude for the filtered data.\n",
    "    - Applies plain number formatting to axes to enhance readability.\n",
    "\n",
    "Returns:\n",
    "    None. Displays a matplotlib plot showing spatial density of problematic points.\n",
    "\"\"\"\n",
    "\n",
    "df = merged_dfs\n",
    "df_danger = df[df['isProblem'] == 1]\n",
    "df_danger = df[df['vehicleId'] == 15]\n",
    "\n",
    "\n",
    "sns.set_theme(style=\"ticks\")\n",
    "fig, ax = plt.subplots()\n",
    "#sns.jointplot(x=df_danger['lng'], y=df_danger['lat'], kind=\"hex\", color=\"#4CB391\", ax=ax)\n",
    "ax.hexbin(x=df_danger['lng'], y=df_danger['lat'])\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "\n",
    "plt.gca().xaxis.set_major_formatter(ScalarFormatter())\n",
    "plt.gca().yaxis.set_major_formatter(ScalarFormatter())\n",
    "plt.ticklabel_format(style='plain', axis='both')  # Disable scientific notation\n",
    "\n",
    "\n",
    "ax.set_title('Density of problem points on spatial coordinates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:12.613965Z",
     "start_time": "2025-02-01T18:48:12.598846Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to ./Plots/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_head = 400\n",
    "\n",
    "df15 = df[df[\"vehicleId\"] == 15]\n",
    "df15 = df15.head(_head)\n",
    "df15 = df15.reset_index(drop=True)\n",
    "\n",
    "df15_problem = df15[df15['isProblem'] == 1]\n",
    "\n",
    "plt.title(f\"Acceleration Variance for {_head} data points\")\n",
    "plt.xlabel(\"Trajectory data point indexes\")\n",
    "plt.ylabel(\"Acceleration (km\\h^2)\")\n",
    "plt.plot(df15.index, df15['acceleration'])\n",
    "plt.grid()\n",
    "plt.scatter(df15_problem.index, df15_problem['acceleration'], color='red')\n",
    "\n",
    "plot_save_path = os.path.join(PLOT_FOLDER_PATH, \"accelartion_variance.png\")\n",
    "plt.savefig(plot_save_path)\n",
    "print(f\"Plot saved to {PLOT_FOLDER_PATH}\")\n",
    "\n",
    "plt.show()\n",
    "len(df15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:17.330420Z",
     "start_time": "2025-02-01T18:48:17.325963Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# #### MOCK DATA #####\n",
    "#\n",
    "# data = {\n",
    "#     'lng': np.random.uniform(-180, 180, 200),\n",
    "#     'lat': np.random.uniform(-90, 90, 200)\n",
    "# }\n",
    "# df = pd.DataFrame(data)\n",
    "# df_danger = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:17.808617Z",
     "start_time": "2025-02-01T18:48:17.802262Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:18.846543Z",
     "start_time": "2025-02-01T18:48:18.474283Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17745/2614305709.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_danger.loc[:, 'cluster'] = clusters  # Adding cluster labels to DataFrame\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to ./Plots/\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Performs DBSCAN clustering on spatial coordinates of problematic data points and visualizes the resulting clusters.\n",
    "\n",
    "Steps:\n",
    "    - Extracts 'lng' and 'lat' columns from `df_danger`.\n",
    "    - Standardizes the coordinates for improved clustering performance.\n",
    "    - Applies the DBSCAN algorithm with specified `eps` and `min_samples` parameters.\n",
    "    - Filters out noise points (cluster = -1) and retains only valid clusters.\n",
    "    - Plots the clustered points with distinct colors and saves the figure to `PLOT_FOLDER_PATH`.\n",
    "\n",
    "Returns:\n",
    "    None. Displays and saves a scatter plot of geospatial clusters.\n",
    "\"\"\"\n",
    "\n",
    "# Extracting the coordinates\n",
    "coords = df_danger[['lng', 'lat']].values\n",
    "\n",
    "# Standardizing the data for better clustering performance\n",
    "scaler = StandardScaler()\n",
    "coords_scaled = scaler.fit_transform(coords)\n",
    "\n",
    "# Applying DBSCAN\n",
    "dbscan = DBSCAN(eps=0.02, min_samples=4)  # Adjust eps as needed\n",
    "clusters = dbscan.fit_predict(coords_scaled)\n",
    "\n",
    "df_danger.loc[:, 'cluster'] = clusters  # Adding cluster labels to DataFrame\n",
    "\n",
    "\n",
    "df_danger_cluster = df_danger[df_danger['cluster'] > -1]\n",
    "\n",
    "\n",
    "# %matplotlib inline\n",
    "# Plotting the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df_danger_cluster['lng'], df_danger_cluster['lat'], c=df_danger_cluster['cluster'], cmap='tab10', edgecolors='k', alpha=0.7)\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('DBSCAN Clustering of Geospatial Data')\n",
    "plt.colorbar(label='Cluster')\n",
    "\n",
    "# Save the plot\n",
    "# Define the path to save the plot\n",
    "plot_save_path = os.path.join(PLOT_FOLDER_PATH, \"DBSCAN_Clustering_of_Geospatial_Data.png\")\n",
    "plt.savefig(plot_save_path, bbox_inches='tight')\n",
    "print(f\"Plot saved to {PLOT_FOLDER_PATH}\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:18.984524Z",
     "start_time": "2025-02-01T18:48:18.979522Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['vehicleId', 'lat', 'lng', 'velocity', 'dateStoredHuman',\n",
       "       'seconds_diff', 'trip_id', 'distance_m', 'bearing', 'orientation',\n",
       "       'bearing_diff', 'velocity_diff', 'acceleration', 'isProblem',\n",
       "       'cluster'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_danger.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vehicleId</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>velocity</th>\n",
       "      <th>seconds_diff</th>\n",
       "      <th>trip_id</th>\n",
       "      <th>distance_m</th>\n",
       "      <th>bearing</th>\n",
       "      <th>bearing_diff</th>\n",
       "      <th>velocity_diff</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>isProblem</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1517.0</td>\n",
       "      <td>1517.000000</td>\n",
       "      <td>1517.000000</td>\n",
       "      <td>1517.000000</td>\n",
       "      <td>1517.000000</td>\n",
       "      <td>1517.000000</td>\n",
       "      <td>1517.000000</td>\n",
       "      <td>1517.000000</td>\n",
       "      <td>1517.000000</td>\n",
       "      <td>1517.000000</td>\n",
       "      <td>1517.000000</td>\n",
       "      <td>1517.000000</td>\n",
       "      <td>1517.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15.0</td>\n",
       "      <td>37.514896</td>\n",
       "      <td>22.382625</td>\n",
       "      <td>19.600527</td>\n",
       "      <td>4.143705</td>\n",
       "      <td>139.842452</td>\n",
       "      <td>12.565485</td>\n",
       "      <td>205.088664</td>\n",
       "      <td>83.951365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014870</td>\n",
       "      <td>0.127884</td>\n",
       "      <td>1.253131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006654</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>12.671096</td>\n",
       "      <td>5.510165</td>\n",
       "      <td>69.293158</td>\n",
       "      <td>21.848633</td>\n",
       "      <td>108.365935</td>\n",
       "      <td>101.405398</td>\n",
       "      <td>8.033324</td>\n",
       "      <td>0.671664</td>\n",
       "      <td>0.334071</td>\n",
       "      <td>4.543167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>15.0</td>\n",
       "      <td>37.506782</td>\n",
       "      <td>22.360795</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-39.000000</td>\n",
       "      <td>-4.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>15.0</td>\n",
       "      <td>37.510752</td>\n",
       "      <td>22.380318</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>4.510000</td>\n",
       "      <td>104.289875</td>\n",
       "      <td>5.770000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>-0.277778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15.0</td>\n",
       "      <td>37.510957</td>\n",
       "      <td>22.385692</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>9.220000</td>\n",
       "      <td>246.743638</td>\n",
       "      <td>27.530000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.0</td>\n",
       "      <td>37.520865</td>\n",
       "      <td>22.386168</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>16.770000</td>\n",
       "      <td>291.443161</td>\n",
       "      <td>155.770000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.0</td>\n",
       "      <td>37.532238</td>\n",
       "      <td>22.387758</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>552.080000</td>\n",
       "      <td>359.286728</td>\n",
       "      <td>356.350000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       vehicleId          lat          lng     velocity  seconds_diff  \\\n",
       "count     1517.0  1517.000000  1517.000000  1517.000000   1517.000000   \n",
       "mean        15.0    37.514896    22.382625    19.600527      4.143705   \n",
       "std          0.0     0.006654     0.005373    12.671096      5.510165   \n",
       "min         15.0    37.506782    22.360795     0.000000      0.000000   \n",
       "25%         15.0    37.510752    22.380318    10.000000      1.000000   \n",
       "50%         15.0    37.510957    22.385692    18.000000      2.000000   \n",
       "75%         15.0    37.520865    22.386168    28.000000      5.000000   \n",
       "max         15.0    37.532238    22.387758    55.000000     46.000000   \n",
       "\n",
       "           trip_id   distance_m      bearing  bearing_diff  velocity_diff  \\\n",
       "count  1517.000000  1517.000000  1517.000000   1517.000000    1517.000000   \n",
       "mean    139.842452    12.565485   205.088664     83.951365       0.000000   \n",
       "std      69.293158    21.848633   108.365935    101.405398       8.033324   \n",
       "min       1.000000     0.000000     0.000000      0.000000     -39.000000   \n",
       "25%      79.000000     4.510000   104.289875      5.770000      -4.000000   \n",
       "50%     160.000000     9.220000   246.743638     27.530000       0.000000   \n",
       "75%     207.000000    16.770000   291.443161    155.770000       3.000000   \n",
       "max     208.000000   552.080000   359.286728    356.350000      39.000000   \n",
       "\n",
       "       acceleration    isProblem      cluster  \n",
       "count   1517.000000  1517.000000  1517.000000  \n",
       "mean       0.014870     0.127884     1.253131  \n",
       "std        0.671664     0.334071     4.543167  \n",
       "min       -4.444444     0.000000    -1.000000  \n",
       "25%       -0.277778     0.000000    -1.000000  \n",
       "50%        0.000000     0.000000     0.000000  \n",
       "75%        0.277778     0.000000     0.000000  \n",
       "max        6.666667     1.000000    19.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_danger.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Showing convex hulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:21.258667Z",
     "start_time": "2025-02-01T18:48:21.249980Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:21.832752Z",
     "start_time": "2025-02-01T18:48:21.685594Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17745/363052028.py:22: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  colors = plt.cm.get_cmap(\"tab10\", len(unique_clusters))  # Set of distinct colors for clusters\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Plots DBSCAN clusters with convex hulls overlaid to highlight the spatial extent of each cluster.\n",
    "\n",
    "Args:\n",
    "    df (pd.DataFrame): DataFrame containing clustered data with 'lng', 'lat', and 'cluster' columns.\n",
    "    clusters (array-like): Array of cluster labels assigned to each point (e.g., from DBSCAN).\n",
    "    normal_df_points (pd.DataFrame): DataFrame of non-problematic data points to plot in gray for reference.\n",
    "\n",
    "Functionality:\n",
    "    - Plots each cluster with a distinct color and labels.\n",
    "    - Overlays convex hulls around clusters with at least 3 points to show cluster boundaries.\n",
    "    - Adds non-clustered (normal) points in gray.\n",
    "    - Adds a colorbar for cluster identification.\n",
    "    - Saves the resulting figure to `PLOT_FOLDER_PATH`.\n",
    "\n",
    "Returns:\n",
    "    None. Displays and saves a clustered map with convex hull overlays.\n",
    "\"\"\"\n",
    "\n",
    "def plot_convex_hulls(df, clusters, normal_df_points):\n",
    "    unique_clusters = set(clusters)\n",
    "    colors = plt.cm.get_cmap(\"tab10\", len(unique_clusters))  # Set of distinct colors for clusters\n",
    "\n",
    "    fig, ax = plt.subplots()  # Create figure and axis objects\n",
    "\n",
    "    # Plot points first for colorbar\n",
    "    for cluster in unique_clusters:\n",
    "        if cluster == -1:\n",
    "            continue  # Skip noise points\n",
    "        cluster_points = df[df['cluster'] == cluster][['lng', 'lat']].values\n",
    "        ax.scatter(cluster_points[:, 0], cluster_points[:, 1], label=f'Cluster {cluster}', c=[colors(cluster)], s=10)\n",
    "\n",
    "    ax.scatter(normal_df_points['lng'], normal_df_points['lat'], c='gray', alpha=0.5)\n",
    "\n",
    "    # Plot Convex Hulls\n",
    "    for cluster in unique_clusters:\n",
    "        if cluster == -1:\n",
    "            continue  # Skip noise points\n",
    "        cluster_points = df[df['cluster'] == cluster][['lng', 'lat']].values\n",
    "        if len(cluster_points) >= 3:  # Convex hull requires at least 3 points\n",
    "            hull = ConvexHull(cluster_points)\n",
    "            hull_points = np.append(hull.vertices, hull.vertices[0])  # Close the loop\n",
    "            ax.plot(cluster_points[hull_points, 0], cluster_points[hull_points, 1], 'r-')\n",
    "\n",
    "    ax.set_xlabel('Longitude')\n",
    "    ax.set_ylabel('Latitude')\n",
    "    ax.set_title('DBSCAN Clustering of Geospatial Data with Convex Hulls')\n",
    "\n",
    "    # Create colorbar using scatter points\n",
    "    cb = fig.colorbar(plt.cm.ScalarMappable(cmap=\"tab10\", norm=plt.Normalize(vmin=min(unique_clusters), vmax=max(unique_clusters))),\n",
    "                      ax=ax, label='Cluster')\n",
    "    \n",
    "    # Save the plot\n",
    "    plot_save_path = os.path.join(PLOT_FOLDER_PATH, \"DBSCAN_Clustering_of_Geospatial_Data_with_Convex_Hulls\")\n",
    "    plt.savefig(plot_save_path, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_convex_hulls(df_danger_cluster, clusters, df[df['isProblem'] == 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get specific **Cluster's BBOX**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0: {'min_lng': 22.384585, 'max_lng': 22.3870483, 'min_lat': 37.5102516, 'max_lat': 37.51159}\n",
      "Cluster 1: {'min_lng': 22.3874233, 'max_lng': 22.3875216, 'min_lat': 37.5106983, 'max_lat': 37.5108166}\n",
      "Cluster 2: {'min_lng': 22.3868549, 'max_lng': 22.3870566, 'min_lat': 37.5103233, 'max_lat': 37.5105766}\n",
      "Cluster 3: {'min_lng': 22.3839199, 'max_lng': 22.3841449, 'min_lat': 37.5111466, 'max_lat': 37.5112433}\n",
      "Cluster 4: {'min_lng': 22.3842799, 'max_lng': 22.3846183, 'min_lat': 37.5108516, 'max_lat': 37.5110883}\n",
      "Cluster 5: {'min_lng': 22.3833466, 'max_lng': 22.3834666, 'min_lat': 37.5121433, 'max_lat': 37.51235}\n",
      "Cluster 6: {'min_lng': 22.3835516, 'max_lng': 22.3836183, 'min_lat': 37.5140999, 'max_lat': 37.5145033}\n",
      "Cluster 7: {'min_lng': 22.3814849, 'max_lng': 22.3816016, 'min_lat': 37.5184116, 'max_lat': 37.5186266}\n",
      "Cluster 8: {'min_lng': 22.3822883, 'max_lng': 22.3824266, 'min_lat': 37.5191233, 'max_lat': 37.5194066}\n",
      "Cluster 9: {'min_lng': 22.3803183, 'max_lng': 22.380515, 'min_lat': 37.52059, 'max_lat': 37.5209333}\n",
      "Cluster 10: {'min_lng': 22.3804933, 'max_lng': 22.3807333, 'min_lat': 37.521175, 'max_lat': 37.5217549}\n",
      "Cluster 11: {'min_lng': 22.3785466, 'max_lng': 22.3789333, 'min_lat': 37.5222833, 'max_lat': 37.5225433}\n",
      "Cluster 12: {'min_lng': 22.377735, 'max_lng': 22.3781383, 'min_lat': 37.5250533, 'max_lat': 37.5252883}\n",
      "Cluster 13: {'min_lng': 22.37584, 'max_lng': 22.3759533, 'min_lat': 37.5227833, 'max_lat': 37.5232233}\n",
      "Cluster 14: {'min_lng': 22.3735733, 'max_lng': 22.373845, 'min_lat': 37.5210816, 'max_lat': 37.5212716}\n",
      "Cluster 15: {'min_lng': 22.3728549, 'max_lng': 22.3731483, 'min_lat': 37.520865, 'max_lat': 37.5210016}\n",
      "Cluster 16: {'min_lng': 22.3729149, 'max_lng': 22.373, 'min_lat': 37.5282783, 'max_lat': 37.5285433}\n",
      "Cluster 17: {'min_lng': 22.3729166, 'max_lng': 22.3731783, 'min_lat': 37.5286, 'max_lat': 37.5290066}\n",
      "Cluster 18: {'min_lng': 22.3712416, 'max_lng': 22.3715549, 'min_lat': 37.5306633, 'max_lat': 37.5312666}\n",
      "Cluster 19: {'min_lng': 22.3723283, 'max_lng': 22.3723533, 'min_lat': 37.5318199, 'max_lat': 37.5321216}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Computes the bounding boxes (min/max longitude and latitude) for each DBSCAN cluster.\n",
    "\n",
    "Args:\n",
    "    df (pd.DataFrame): DataFrame containing geospatial points with 'lng', 'lat', and 'cluster' columns.\n",
    "    clusters (array-like): List or array of cluster labels corresponding to each point.\n",
    "\n",
    "Returns:\n",
    "    dict: A dictionary where each key is a cluster ID and the value is another dictionary with:\n",
    "        - 'min_lng': Minimum longitude of the cluster\n",
    "        - 'max_lng': Maximum longitude of the cluster\n",
    "        - 'min_lat': Minimum latitude of the cluster\n",
    "        - 'max_lat': Maximum latitude of the cluster\n",
    "\n",
    "Notes:\n",
    "    - Noise points (cluster label -1) are excluded from the results.\n",
    "    - Useful for visualizing or exporting the spatial extent of each cluster.\n",
    "\"\"\"\n",
    "\n",
    "def get_bbox_of_clusters(df, clusters):\n",
    "    cluster_bboxes = {}\n",
    "\n",
    "    # Iterate over unique clusters (excluding -1 for noise)\n",
    "    unique_clusters = sorted(set(clusters) - {-1})  # Exclude noise points (-1)\n",
    "\n",
    "    for cluster in unique_clusters:\n",
    "        # Filter the points of the current cluster\n",
    "        cluster_points = df[df['cluster'] == cluster][['lng', 'lat']]\n",
    "        \n",
    "        # Get the minimum and maximum lng and lat for the bounding box\n",
    "        min_lng = cluster_points['lng'].min()\n",
    "        max_lng = cluster_points['lng'].max()\n",
    "        min_lat = cluster_points['lat'].min()\n",
    "        max_lat = cluster_points['lat'].max()\n",
    "\n",
    "        # Store the bounding box for the current cluster\n",
    "        cluster_bboxes[cluster] = {\n",
    "            'min_lng': min_lng,\n",
    "            'max_lng': max_lng,\n",
    "            'min_lat': min_lat,\n",
    "            'max_lat': max_lat\n",
    "        }\n",
    "\n",
    "    return cluster_bboxes\n",
    "\n",
    "cluster_bboxes = get_bbox_of_clusters(df_danger_cluster, clusters)\n",
    "\n",
    "# Display the bounding boxes for each cluster\n",
    "for cluster, bbox in cluster_bboxes.items():\n",
    "    print(f\"Cluster {cluster}: {bbox}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:29.581721Z",
     "start_time": "2025-02-01T18:48:29.577151Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Prepare the DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:29.755180Z",
     "start_time": "2025-02-01T18:48:29.750637Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       vehicleId        lat        lng      dateStoredHuman     bearing  \\\n",
      "0              1  37.510833  22.385710  2024-06-06 17:02:17  137.402376   \n",
      "1              1  37.510603  22.385977  2024-06-06 17:02:20  312.778670   \n",
      "2              1  37.510640  22.385927  2024-06-06 17:02:25  351.785725   \n",
      "3              1  37.510750  22.385907  2024-06-06 17:02:31  307.481149   \n",
      "4              1  37.510877  22.385698  2024-06-06 17:02:37  318.388767   \n",
      "...          ...        ...        ...                  ...         ...   \n",
      "33310         20  37.531627  22.369163  2025-05-08 12:02:00   96.979502   \n",
      "33311         20  37.531603  22.369403  2025-05-08 12:02:02   98.786289   \n",
      "33312         20  37.531575  22.369635  2025-05-08 12:02:04   95.545935   \n",
      "33313         20  37.531545  22.370023  2025-05-08 12:02:05   95.436396   \n",
      "33314         20  37.531525  22.370288  2025-05-08 12:02:08         NaN   \n",
      "\n",
      "      orientation  seconds_diff  trip_id  \n",
      "0       Southeast           0.0        0  \n",
      "1       Northwest           3.0        0  \n",
      "2           North           5.0        0  \n",
      "3       Northwest           6.0        0  \n",
      "4       Northwest           6.0        0  \n",
      "...           ...           ...      ...  \n",
      "33310        East           2.0       17  \n",
      "33311        East           2.0       17  \n",
      "33312        East           2.0       17  \n",
      "33313        East           1.0       17  \n",
      "33314         NaN           3.0       17  \n",
      "\n",
      "[33315 rows x 8 columns]\n",
      "The trip_id with the most rows for vehicleId 1 is: 64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Extracts relevant columns related to vehicle orientation and identifies the most frequent trip for a specific vehicle.\n",
    "\n",
    "Steps:\n",
    "    1. Creates a copy of the merged DataFrame and extracts columns: \n",
    "       'vehicleId', 'lat', 'lng', 'dateStoredHuman', 'bearing', 'orientation', 'seconds_diff', and 'trip_id'.\n",
    "    2. Filters the DataFrame for records with `vehicleId == 1`.\n",
    "    3. Counts the number of entries per `trip_id` for vehicle 1.\n",
    "    4. Identifies and prints the `trip_id` that appears most frequently.\n",
    "\n",
    "Returns:\n",
    "    None (prints the resulting filtered DataFrame and most frequent trip ID for vehicleId 1).\n",
    "\"\"\"\n",
    "\n",
    "# *Get specific columns \n",
    "_ = merged_dfs.copy()\n",
    "bearings_df = _[['vehicleId', 'lat', 'lng', 'dateStoredHuman' ,'bearing', 'orientation', 'seconds_diff', 'trip_id']]\n",
    "print(bearings_df)\n",
    "\n",
    "# Filter for vehicleId == 1\n",
    "df_vehicle1 = df[df['vehicleId'] == 1]\n",
    "\n",
    "# Count occurrences of each trip_id\n",
    "trip_counts = df_vehicle1['trip_id'].value_counts()\n",
    "\n",
    "# Get the trip_id with the highest count\n",
    "most_frequent_trip_id = trip_counts.idxmax()\n",
    "\n",
    "# Display the result\n",
    "print(f\"The trip_id with the most rows for vehicleId 1 is: {most_frequent_trip_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get trip_id's rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:29.911737Z",
     "start_time": "2025-02-01T18:48:29.907023Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     vehicleId        lat        lng  velocity      dateStoredHuman  \\\n",
      "946          1  37.510722  22.387033      16.0  2024-06-08 17:32:23   \n",
      "947          1  37.510692  22.387185       8.0  2024-06-08 17:32:30   \n",
      "948          1  37.510670  22.387042       9.0  2024-06-08 17:32:38   \n",
      "949          1  37.510645  22.386773      22.0  2024-06-08 17:32:41   \n",
      "950          1  37.510685  22.386552      34.0  2024-06-08 17:32:43   \n",
      "\n",
      "     seconds_diff  trip_id  distance_m     bearing orientation  bearing_diff  \\\n",
      "946           0.0       64        0.00  103.998723        East          0.00   \n",
      "947           7.0       64       13.82  259.248208        West        155.25   \n",
      "948           8.0       64       12.90  263.300439        West          4.05   \n",
      "949           3.0       64       23.88  282.783117        West         19.48   \n",
      "950           2.0       64       20.10  277.535628        West          5.25   \n",
      "\n",
      "     velocity_diff  acceleration  isProblem  \n",
      "946          -40.0      0.000000          0  \n",
      "947           -8.0     -0.317460          0  \n",
      "948            1.0      0.034722          0  \n",
      "949           13.0      1.203704          0  \n",
      "950           12.0      1.666667          0  \n"
     ]
    }
   ],
   "source": [
    "print(df[(df['vehicleId'] == 1) & (df['trip_id'] == most_frequent_trip_id)].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot real **directional spread**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1️⃣ Violin Plot (Distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:30.464254Z",
     "start_time": "2025-02-01T18:48:30.459088Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to ./Plots/\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generates a violin plot to visualize the distribution of bearing differences using circular statistics.\n",
    "\n",
    "Steps:\n",
    "    1. Converts the 'bearing_diff' column from degrees to radians for circular statistical analysis.\n",
    "    2. Computes the circular mean and circular standard deviation in radians, then converts them back to degrees.\n",
    "    3. Plots a violin plot of 'bearing_diff' to show its distribution.\n",
    "    4. Overlays vertical lines for:\n",
    "        - Circular mean (solid green line)\n",
    "        - ±1 circular standard deviation (dashed orange lines)\n",
    "    5. Adds labels, legend, and saves the plot to `PLOT_FOLDER_PATH`.\n",
    "\n",
    "Returns:\n",
    "    None (displays and saves the plot).\n",
    "\"\"\"\n",
    "\n",
    "# Convert to radians for circular statistics\n",
    "bearing_diff_rad = np.deg2rad(merged_dfs['bearing_diff'])\n",
    "\n",
    "# Compute circular mean and circular standard deviation\n",
    "circular_mean_rad = circmean(bearing_diff_rad, high=np.pi, low=-np.pi)\n",
    "circular_std_rad = circstd(bearing_diff_rad, high=np.pi, low=-np.pi)\n",
    "\n",
    "# Convert back to degrees for plotting\n",
    "circular_mean_deg = np.rad2deg(circular_mean_rad)\n",
    "circular_std_deg = np.rad2deg(circular_std_rad)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Create the violin plot\n",
    "sns.violinplot(x=merged_dfs['bearing_diff'], inner=\"quartile\", color=\"lightblue\")\n",
    "\n",
    "# Mark the circular mean and circular standard deviation\n",
    "plt.axvline(x=circular_mean_deg, color='green', linestyle='-', label=f'Circular Mean ({circular_mean_deg:.2f}°)')\n",
    "plt.axvline(x=circular_mean_deg + circular_std_deg, color='orange', linestyle='--', label=f'+1σ ({(circular_mean_deg + circular_std_deg):.2f}°)')\n",
    "plt.axvline(x=circular_mean_deg - circular_std_deg, color='orange', linestyle='--', label=f'-1σ ({(circular_mean_deg - circular_std_deg):.2f}°)')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Bearing Difference (Degrees)')\n",
    "plt.title('Violin Plot: Circular Stats of Bearing Difference')\n",
    "\n",
    "# Show legend\n",
    "plt.legend()\n",
    "\n",
    "# Save and display\n",
    "plt.savefig(PLOT_FOLDER_PATH, bbox_inches='tight')\n",
    "print(f\"Plot saved to {PLOT_FOLDER_PATH}\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print((merged_dfs['bearing_diff'] < 0).sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1️⃣ Polar Plot: Bearing Difference Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polar plot saved to ./Plots/Polar_Plot\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generates a polar histogram to visualize the distribution of bearing differences as circular data.\n",
    "\n",
    "Steps:\n",
    "    1. Converts 'bearing_diff' from degrees to radians and wraps it to [0, 2π] for circular consistency.\n",
    "    2. Bins the data into `num_bins` angular bins (default is 36 for 10-degree resolution).\n",
    "    3. Plots a polar bar chart representing frequency of bearing differences across angular bins.\n",
    "    4. Computes and overlays the circular mean as a red dashed line.\n",
    "    5. Configures plot orientation (0° at the top, clockwise direction) and adds legend/title.\n",
    "    6. Saves the plot to `PLOT_FOLDER_PATH` and displays it.\n",
    "\n",
    "Returns:\n",
    "    None (displays and saves the polar plot).\n",
    "\"\"\"\n",
    "\n",
    "# Convert to radians and wrap angles to [0, 2π]\n",
    "bearing_diff_rad = np.deg2rad(merged_dfs['bearing_diff'] % 360)\n",
    "\n",
    "# Define number of bins (adjust based on resolution you want)\n",
    "num_bins = 36  # 10-degree bins\n",
    "\n",
    "# Create histogram\n",
    "counts, bin_edges = np.histogram(bearing_diff_rad, bins=num_bins)\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "# Create polar plot\n",
    "plt.figure(figsize=(6, 6))\n",
    "ax = plt.subplot(111, polar=True)\n",
    "\n",
    "# Plot histogram as bars\n",
    "bars = ax.bar(bin_centers, counts, width=(2 * np.pi / num_bins), bottom=0.0, color='lightblue', edgecolor='k')\n",
    "\n",
    "circular_mean_rad = circmean(bearing_diff_rad, high=2*np.pi, low=0)\n",
    "ax.plot([circular_mean_rad, circular_mean_rad], [0, max(counts)], color='red', linestyle='--', linewidth=2, label='Circular Mean')\n",
    "\n",
    "# Format and show\n",
    "ax.set_theta_zero_location('N')  # 0° at the top\n",
    "ax.set_theta_direction(-1)       # Clockwise\n",
    "plt.title(\"Polar Plot: Bearing Difference Distribution\")\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# Save and display\n",
    "plot_save_path = os.path.join(PLOT_FOLDER_PATH, \"Polar_Plot\")\n",
    "plt.savefig(plot_save_path, bbox_inches='tight')\n",
    "print(f\"Polar plot saved to {plot_save_path}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-01T18:48:30.648854Z",
     "start_time": "2025-02-01T18:48:30.643996Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "###  2️⃣ Boxplot (Detect Outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boxplot saved to ./Plots/\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generates a polar histogram to visualize the distribution of bearing differences as circular data.\n",
    "\n",
    "Steps:\n",
    "    1. Converts 'bearing_diff' from degrees to radians and wraps it to [0, 2π] for circular consistency.\n",
    "    2. Bins the data into `num_bins` angular bins (default is 36 for 10-degree resolution).\n",
    "    3. Plots a polar bar chart representing frequency of bearing differences across angular bins.\n",
    "    4. Computes and overlays the circular mean as a red dashed line.\n",
    "    5. Configures plot orientation (0° at the top, clockwise direction) and adds legend/title.\n",
    "    6. Saves the plot to `PLOT_FOLDER_PATH` and displays it.\n",
    "\n",
    "Returns:\n",
    "    None (displays and saves the polar plot).\n",
    "\"\"\"\n",
    "\n",
    "# Convert to radians for circular statistics\n",
    "bearing_diff_rad = np.deg2rad(merged_dfs['bearing_diff'])\n",
    "\n",
    "# Compute circular mean and circular standard deviation\n",
    "circular_mean_rad = circmean(bearing_diff_rad, high=np.pi, low=-np.pi)\n",
    "circular_std_rad = circstd(bearing_diff_rad, high=np.pi, low=-np.pi)\n",
    "\n",
    "# Convert back to degrees for plotting\n",
    "circular_mean_deg = np.rad2deg(circular_mean_rad)\n",
    "circular_std_deg = np.rad2deg(circular_std_rad)\n",
    "\n",
    "# Create the boxplot\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(x=merged_dfs['bearing_diff'], color='lightgreen', fliersize=3)\n",
    "\n",
    "# Overlay circular mean and ±1σ\n",
    "plt.axvline(x=circular_mean_deg, color='blue', linestyle='-', label=f'Circular Mean ({circular_mean_deg:.2f}°)')\n",
    "plt.axvline(x=circular_mean_deg + circular_std_deg, color='red', linestyle='--', label=f'+1σ ({(circular_mean_deg + circular_std_deg):.2f}°)')\n",
    "plt.axvline(x=circular_mean_deg - circular_std_deg, color='red', linestyle='--', label=f'-1σ ({(circular_mean_deg - circular_std_deg):.2f}°)')\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel('Bearing Difference (Degrees)')\n",
    "plt.title('Boxplot: Circular Stats of Bearing Difference')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save and display\n",
    "plot_save_path = PLOT_FOLDER_PATH.replace(\".png\", \"_boxplot.png\")\n",
    "plt.savefig(plot_save_path, bbox_inches='tight')\n",
    "print(f\"Boxplot saved to {plot_save_path}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3️⃣ Color by Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to ./Plots/Scatter_bearings_vs_seconds_diff_density.png\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generates a scatter plot visualizing the relationship between 'bearing_diff' and 'seconds_diff', with point density indicated by color.\n",
    "\n",
    "Steps:\n",
    "    1. Extracts the 'seconds_diff' and 'bearing_diff' columns from `merged_dfs`.\n",
    "    2. Calculates the density of points using `gaussian_kde` for a smoother representation.\n",
    "    3. Plots a scatter plot where the color of each point represents its density.\n",
    "    4. Adds a colorbar to indicate the point density.\n",
    "    5. Configures plot labels, title, and grid for better visualization.\n",
    "    6. Saves the plot as an image file in the specified `PLOT_FOLDER_PATH` and displays it.\n",
    "\n",
    "Returns:\n",
    "    None (displays and saves the scatter plot).\n",
    "\"\"\"\n",
    "\n",
    "x = merged_dfs['seconds_diff']\n",
    "y = merged_dfs['bearing_diff']\n",
    "\n",
    "# Calculate point density\n",
    "xy = np.vstack([x, y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(x, y, c=z, cmap='viridis', s=50, edgecolors='none', alpha=0.8)\n",
    "plt.colorbar(scatter, label='Point Density')\n",
    "plt.title('Scatter Plot of Bearing Difference vs. Seconds Difference')\n",
    "plt.xlabel('Seconds Difference')\n",
    "plt.ylabel('Bearing Difference')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save\n",
    "plot_save_path = os.path.join(PLOT_FOLDER_PATH, \"Scatter_bearings_vs_seconds_diff_density.png\")\n",
    "plt.savefig(plot_save_path, bbox_inches='tight')\n",
    "print(f\"Plot saved to {plot_save_path}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4️⃣ Scatter + Trend Line + Thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static plot saved to ./Plots/Enhanced_Scatter_with_LOESS.png\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generates an enhanced scatter plot showing the relationship between 'bearing_diff' and 'seconds_diff',\n",
    "with density coloring and a LOWESS (Locally Weighted Scatterplot Smoothing) trend line.\n",
    "\n",
    "Steps:\n",
    "    1. Extracts the 'seconds_diff' and 'bearing_diff' columns from `merged_dfs`.\n",
    "    2. Computes the point density using `gaussian_kde` for density-based coloring.\n",
    "    3. Applies LOWESS smoothing to the 'bearing_diff' values based on 'seconds_diff'.\n",
    "    4. Plots the scatter plot with density coloring and a LOWESS trend line.\n",
    "    5. Optionally adds horizontal threshold lines at ±45° to highlight specific ranges.\n",
    "    6. Configures plot title, labels, color bar, grid, and legend for clarity.\n",
    "    7. Saves the plot as an image file in the specified `PLOT_FOLDER_PATH` and displays it.\n",
    "\n",
    "Returns:\n",
    "    None (displays and saves the enhanced scatter plot).\n",
    "\"\"\"\n",
    "\n",
    "x = merged_dfs['seconds_diff']\n",
    "y = merged_dfs['bearing_diff']\n",
    "\n",
    "# Calculate density\n",
    "xy = np.vstack([x, y])\n",
    "z = gaussian_kde(xy)(xy)\n",
    "\n",
    "# LOWESS smoothing\n",
    "lowess = sm.nonparametric.lowess\n",
    "smoothed = lowess(y, x, frac=0.2)  # Adjust frac for smoothness\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Scatter colored by density\n",
    "scatter = plt.scatter(x, y, c=z, cmap='viridis', s=40, edgecolors='none', alpha=0.7, label='Data Points')\n",
    "\n",
    "# LOWESS line\n",
    "plt.plot(smoothed[:, 0], smoothed[:, 1], color='red', linewidth=2, label='LOWESS Trend')\n",
    "\n",
    "# Optional thresholds (customize as needed)\n",
    "plt.axhline(y=45, color='orange', linestyle='--', linewidth=1, label='Upper Threshold (45°)')\n",
    "plt.axhline(y=-45, color='orange', linestyle='--', linewidth=1, label='Lower Threshold (-45°)')\n",
    "\n",
    "plt.title('Bearing Difference vs. Seconds Difference (with Trend)')\n",
    "plt.xlabel('Seconds Difference')\n",
    "plt.ylabel('Bearing Difference')\n",
    "plt.colorbar(scatter, label='Point Density')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save\n",
    "plot_save_path = os.path.join(PLOT_FOLDER_PATH, \"Enhanced_Scatter_with_LOESS.png\")\n",
    "plt.savefig(plot_save_path, bbox_inches='tight')\n",
    "print(f\"Static plot saved to {plot_save_path}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5️⃣ KDE Plot for Angular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static plot saved to ./Plots/KDE_of_Bearing_Differences_(Wrapped).png\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generates a Kernel Density Estimate (KDE) plot for the wrapped bearing differences.\n",
    "\n",
    "Steps:\n",
    "    1. Wraps the 'bearing_diff' angles from the `merged_dfs` DataFrame to be between -180 and 180 degrees.\n",
    "    2. Performs a KDE estimation to visualize the distribution of wrapped bearing differences.\n",
    "    3. Plots the KDE curve along with vertical lines indicating the circular mean and ±1 standard deviation.\n",
    "    4. Adds labels, grid, and a legend for clarity.\n",
    "    5. Saves the resulting plot as a PNG image in the specified `PLOT_FOLDER_PATH` and displays it.\n",
    "\n",
    "Returns:\n",
    "    None (displays and saves the KDE plot).\n",
    "\"\"\"\n",
    "\n",
    "# Wrap angles between -180 and 180\n",
    "angles_deg = merged_dfs['bearing_diff']\n",
    "angles_deg_wrapped = ((angles_deg + 180) % 360) - 180\n",
    "\n",
    "# KDE estimation\n",
    "kde = gaussian_kde(angles_deg_wrapped)\n",
    "x_vals = np.linspace(-180, 180, 360)\n",
    "kde_vals = kde(x_vals)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x_vals, kde_vals, color='purple', label='KDE')\n",
    "plt.axvline(x=circular_mean_deg, color='blue', linestyle='-', label='Circular Mean')\n",
    "plt.axvline(x=circular_mean_deg + circular_std_deg, color='red', linestyle='--', label='+1σ')\n",
    "plt.axvline(x=circular_mean_deg - circular_std_deg, color='red', linestyle='--', label='-1σ')\n",
    "plt.title(\"KDE of Bearing Differences (Wrapped)\")\n",
    "plt.xlabel(\"Bearing Difference (Degrees)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save\n",
    "plot_save_path = os.path.join(PLOT_FOLDER_PATH, \"KDE_of_Bearing_Differences_(Wrapped).png\")\n",
    "plt.savefig(plot_save_path, bbox_inches='tight')\n",
    "print(f\"Static plot saved to {plot_save_path}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6️⃣ Circular Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static plot saved to ./Plots/Circular_Heatmap.png\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generates a 2D circular heatmap that visualizes the joint distribution of bearing differences (angles) and their magnitudes.\n",
    "\n",
    "Steps:\n",
    "    1. Creates bins for angles (ranging from -π to π) and magnitudes (ranging from 0 to the maximum bearing difference).\n",
    "    2. Computes the 2D histogram using `np.histogram2d` to capture the density of bearing differences in the defined bins.\n",
    "    3. Uses a polar plot (`ax.pcolormesh`) to display the heatmap on a circular coordinate system.\n",
    "    4. Adds a colorbar for reference, and labels the axes for clarity.\n",
    "    5. Saves the resulting plot as a PNG image in the specified `PLOT_FOLDER_PATH` and displays it.\n",
    "\n",
    "Returns:\n",
    "    None (displays and saves the circular heatmap).\n",
    "\"\"\"\n",
    "\n",
    "# Create 2D histogram: angle + magnitude or time\n",
    "angle_bins = np.linspace(-np.pi, np.pi, 36)\n",
    "magnitude_bins = np.linspace(0, merged_dfs['bearing_diff'].max(), 20)\n",
    "\n",
    "H, _, _ = np.histogram2d(bearing_diff_rad, merged_dfs['bearing_diff'], bins=[angle_bins, magnitude_bins])\n",
    "\n",
    "theta, r = np.meshgrid(angle_bins[:-1], magnitude_bins[:-1])\n",
    "plt.figure(figsize=(6, 6))\n",
    "ax = plt.subplot(111, polar=True)\n",
    "heatmap = ax.pcolormesh(theta, r, H.T, cmap='plasma')\n",
    "plt.colorbar(heatmap, label='Density')\n",
    "ax.set_title(\"Circular Heatmap\")\n",
    "plt.tight_layout()\n",
    "# Save\n",
    "plot_save_path = os.path.join(PLOT_FOLDER_PATH, \"Circular_Heatmap.png\")\n",
    "plt.savefig(plot_save_path, bbox_inches='tight')\n",
    "print(f\"Static plot saved to {plot_save_path}\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7️⃣ Combine Plots in a Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static plot saved to ./Plots/Various_Views_of_Bearing_Differences\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generates a set of four plots to visualize the distribution of bearing differences.\n",
    "\n",
    "Steps:\n",
    "    1. Creates a 2x2 subplot layout with the following visualizations:\n",
    "        - Top-left: A boxplot of bearing differences.\n",
    "        - Top-right: A violin plot of bearing differences.\n",
    "        - Bottom-left: A histogram of bearing differences with a kernel density estimate (KDE).\n",
    "        - Bottom-right: A histogram of bearing differences in radians.\n",
    "    2. Adjusts the layout for a clean presentation and sets the main title.\n",
    "    3. Saves the entire figure as a PNG image in the specified `PLOT_FOLDER_PATH` and displays it.\n",
    "\n",
    "Returns:\n",
    "    None (displays and saves the figure containing multiple visualizations of bearing differences).\n",
    "\"\"\"\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "sns.boxplot(x=merged_dfs['bearing_diff'], ax=axs[0, 0])\n",
    "sns.violinplot(x=merged_dfs['bearing_diff'], ax=axs[0, 1])\n",
    "sns.histplot(merged_dfs['bearing_diff'], bins=30, kde=True, ax=axs[1, 0])\n",
    "axs[1, 1].hist(bearing_diff_rad, bins=36)\n",
    "axs[1, 1].set_title('Histogram (Radians)')\n",
    "\n",
    "fig.suptitle(\"Various Views of Bearing Differences\")\n",
    "plt.tight_layout()\n",
    "# Save\n",
    "plot_save_path = os.path.join(PLOT_FOLDER_PATH, \"Various_Views_of_Bearing_Differences\")\n",
    "plt.savefig(plot_save_path, bbox_inches='tight')\n",
    "print(f\"Static plot saved to {plot_save_path}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot bearings vs 10 seconds_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17745/3608393306.py:41: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  colors = plt.cm.get_cmap('tab20', 20)  # Using the 'tab20' colormap\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This function filters the DataFrame for specific criteria and generates a scatter plot with segments, labels, and a table.\n",
    "\n",
    "Steps:\n",
    "    1. Filters the `merged_dfs` DataFrame to take only the first 20 rows where:\n",
    "        - `seconds_diff` is less than or equal to 10.\n",
    "        - `vehicleId` is 1.\n",
    "        - `trip_id` is 0.\n",
    "    2. Creates a scatter plot with `bearing_diff` on the x-axis and `seconds_diff` on the y-axis.\n",
    "    3. Adds colored segments connecting consecutive points with distinct colors.\n",
    "    4. Labels each point incrementally.\n",
    "    5. Prepares a table displaying orientation information for each row.\n",
    "    6. Adds the table to the plot and formats it.\n",
    "    7. Saves the plot as an image and displays it.\n",
    "\n",
    "Returns:\n",
    "    None (displays and saves the plot showing bearing difference vs seconds difference).\n",
    "\"\"\"\n",
    "\n",
    "# Filter the DataFrame and take only the first 20 rows\n",
    "filtered_df = merged_dfs[\n",
    "    (merged_dfs['seconds_diff'] <= 10) & \n",
    "    (merged_dfs['vehicleId'] == 1) & \n",
    "    (merged_dfs['trip_id'] == 0)\n",
    "]\n",
    "\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Scatter plot (swapped axes)\n",
    "ax.scatter(\n",
    "    filtered_df['bearing_diff'],\n",
    "    filtered_df['seconds_diff'],\n",
    "    alpha=0.6,\n",
    "    edgecolors='w',\n",
    "    label='Points'\n",
    ")\n",
    "\n",
    "# Generate a list of 20 distinct colors using a colormap\n",
    "colors = plt.cm.get_cmap('tab20', 20)  # Using the 'tab20' colormap\n",
    "\n",
    "# Plot segments with changing color for each segment\n",
    "for i in range(len(filtered_df) - 1):\n",
    "    # Get the x and y values for the two points\n",
    "    x_start = filtered_df['bearing_diff'].iloc[i]\n",
    "    y_start = filtered_df['seconds_diff'].iloc[i]\n",
    "    x_end = filtered_df['bearing_diff'].iloc[i + 1]\n",
    "    y_end = filtered_df['seconds_diff'].iloc[i + 1]\n",
    "\n",
    "    # Assign a unique color for each segment from the 'tab20' colormap\n",
    "    color = colors(i)  # Get a different color for each segment\n",
    "\n",
    "    # Plot each segment with its own color\n",
    "    ax.plot([x_start, x_end], [y_start, y_end], color=color, lw=2)\n",
    "\n",
    "# Add incremental labels\n",
    "for i, (x, y) in enumerate(zip(filtered_df['bearing_diff'], filtered_df['seconds_diff'])):\n",
    "    ax.text(x + 0.5, y + 0.1, str(i), fontsize=9, color='black')\n",
    "\n",
    "# Prepare the orientation labels\n",
    "orientation_list = [f\"{i+1}. {orientation}\" for i, orientation in enumerate(filtered_df['orientation'])]\n",
    "\n",
    "# Prepare cell text for the table\n",
    "cell_text = [[orientation] for orientation in orientation_list]\n",
    "\n",
    "# Add the table on the right side of the plot (without color)\n",
    "table = ax.table(cellText=cell_text,\n",
    "                 colLabels=['Orientation'],\n",
    "                 loc='right',\n",
    "                 cellLoc='center',\n",
    "                 colColours=['lightgray'],  # Keep the header background color if desired\n",
    "                 bbox=[1.05, 0, 0.2, 1])  # Adjust bbox for position and size\n",
    "\n",
    "# Labels and title\n",
    "ax.set_title('Bearing Difference vs Seconds Difference (<= 10 seconds)')\n",
    "ax.set_xlabel('Bearing Diff')\n",
    "ax.set_ylabel('Seconds Diff')\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plot_save_path = os.path.join(PLOT_FOLDER_PATH, \"bearings_vs_seconds_diff.png\")\n",
    "plt.savefig(plot_save_path, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trajectory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter trips for calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      vehicleId  trip_id  count\n",
      "0             1        0     13\n",
      "1             1        1      2\n",
      "2             1        2      6\n",
      "3             1        3      4\n",
      "4             1        4      1\n",
      "...         ...      ...    ...\n",
      "1739         20       13    244\n",
      "1740         20       14      6\n",
      "1741         20       15      4\n",
      "1742         20       16      6\n",
      "1743         20       17     15\n",
      "\n",
      "[1744 rows x 3 columns]\n",
      "      vehicleId  trip_id  total_distance_m\n",
      "0             1        0            291.50\n",
      "1             1        1              3.88\n",
      "2             1        2             99.97\n",
      "3             1        3             44.61\n",
      "4             1        4              0.00\n",
      "...         ...      ...               ...\n",
      "1739         20       13           4087.36\n",
      "1740         20       14             80.70\n",
      "1741         20       15             14.02\n",
      "1742         20       16             60.72\n",
      "1743         20       17            951.38\n",
      "\n",
      "[1744 rows x 3 columns]\n",
      "Row difference excluded: 33315 - 29143 = 4172\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This function filters the trips in the dataset based on specific criteria and calculates relevant trip statistics.\n",
    "\n",
    "Steps:\n",
    "    1. Group the `merged_dfs` DataFrame by `vehicleId` and `trip_id` to calculate the number of occurrences (i.e., the count of rows for each trip).\n",
    "    2. Group the `merged_dfs` DataFrame by `vehicleId` and `trip_id` to calculate the total distance traveled for each trip.\n",
    "    3. Filter the trips that have:\n",
    "        - More than 10 rows (observations).\n",
    "        - A total distance traveled greater than 50 meters.\n",
    "    4. Merge the `valid_trips` DataFrame with the original `merged_dfs` DataFrame to filter out trips that don't meet the criteria.\n",
    "    5. Print the difference in rows between the original DataFrame and the filtered DataFrame to show how many rows were excluded.\n",
    "\n",
    "Returns:\n",
    "    filtered_merged_dfs (DataFrame): A new DataFrame containing only the valid trips with the specified criteria.\n",
    "\"\"\"\n",
    "\n",
    "trip_counts = merged_dfs.groupby(['vehicleId', 'trip_id']).size().reset_index(name='count')\n",
    "print(trip_counts)\n",
    "\n",
    "trip_distances = merged_dfs.groupby(['vehicleId', 'trip_id'])['distance_m'].sum().reset_index(name='total_distance_m')\n",
    "print(trip_distances)\n",
    "\n",
    "# *Filter only those trip_ids with more than 10 rows distance traveled > 50\n",
    "valid_trips = trip_counts[(trip_counts['count'] > 10) & (trip_distances['total_distance_m'] > 50.00)]\n",
    "\n",
    "filtered_merged_dfs = merged_dfs.copy()\n",
    "filtered_merged_dfs = pd.merge(merged_dfs, valid_trips[['vehicleId', 'trip_id']], on=['vehicleId', 'trip_id'], how='inner')\n",
    "print(f\"Row difference excluded: {len(merged_dfs)} - {len(filtered_merged_dfs)} = {len(merged_dfs) - len(filtered_merged_dfs)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete previous random vehicle trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function scans through the plot directory and deletes files that match a specific naming pattern.\n",
    "\n",
    "Steps:\n",
    "    1. Define a regular expression pattern (`pattern`) to match filenames of the format: \"Coordinates_for_Vehicle_<vehicleId>_-_Trip_<tripId>_-_<number>_Data_Points.png\".\n",
    "    2. Iterate through all files in the `PLOT_FOLDER_PATH` directory.\n",
    "    3. If the filename matches the defined pattern, try to delete the file.\n",
    "    4. Print the path of the deleted file or an error message if the deletion fails.\n",
    "\n",
    "Arguments:\n",
    "    PLOT_FOLDER_PATH (str): The path to the directory containing the plot files to be checked and potentially deleted.\n",
    "    \n",
    "Returns:\n",
    "    None\n",
    "\"\"\"\n",
    "\n",
    "# Regular expression pattern that matches your generated filenames\n",
    "pattern = re.compile(r'^Coordinates_for_Vehicle_.*_-_Trip_.*_-_\\d+_Data_Points\\.png$')\n",
    "\n",
    "# List all files in the plot directory\n",
    "for filename in os.listdir(PLOT_FOLDER_PATH):\n",
    "    if pattern.match(filename):\n",
    "        file_path = os.path.join(PLOT_FOLDER_PATH, filename)\n",
    "        try:\n",
    "            os.remove(file_path)\n",
    "            print(f\"Deleted: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting {file_path}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot random vehicle ids and trip_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot displayed for Vehicle 9 - Trip 40\n",
      "Plot displayed for Vehicle 9 - Trip 55\n",
      "Plot displayed for Vehicle 1 - Trip 53\n",
      "Plot displayed for Vehicle 5 - Trip 43\n",
      "Plot displayed for Vehicle 7 - Trip 497\n",
      "Plot displayed for Vehicle 1 - Trip 165\n",
      "Plot displayed for Vehicle 1 - Trip 42\n",
      "Plot displayed for Vehicle 1 - Trip 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17745/3243796627.py:28: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(8, 6))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot displayed for Vehicle 7 - Trip 207\n",
      "Plot displayed for Vehicle 8 - Trip 5\n"
     ]
    }
   ],
   "source": [
    "# === Function to Select a Random Trip ===\n",
    "def random_ID(df):\n",
    "    \"\"\"\n",
    "    Randomly selects a vehicleId-trip_id pair from the DataFrame where the trip count is >= 10.\n",
    "    \"\"\"\n",
    "    trip_counts = df.groupby(['vehicleId', 'trip_id']).size().reset_index(name='count')\n",
    "    valid = trip_counts[trip_counts['count'] >= 10]\n",
    "    if valid.empty:\n",
    "        return None, None\n",
    "    sel = valid.sample(1).iloc[0]\n",
    "    return sel['vehicleId'], sel['trip_id']\n",
    "\n",
    "# === Loop to Create Plots for 10 Random Trips ===\n",
    "for i in range(1, 11):\n",
    "    vehicle_id, trip_id = random_ID(merged_dfs)\n",
    "    if vehicle_id is None:\n",
    "        print(f\"Iteration {i} - No valid trip found.\")\n",
    "        continue\n",
    "\n",
    "    # Filter for the chosen trip\n",
    "    filtered_df = merged_dfs[\n",
    "        (merged_dfs['vehicleId'] == vehicle_id) &\n",
    "        (merged_dfs['trip_id']   == trip_id)\n",
    "    ]\n",
    "    num_rows = len(filtered_df)\n",
    "\n",
    "    # --- Plot the Trip ---\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(filtered_df['lng'], filtered_df['lat'], marker='o', linestyle='-',\n",
    "             label=f'Vehicle {vehicle_id} - Trip {trip_id}')\n",
    "    plt.title(f'Vehicle {vehicle_id} - Trip {trip_id} ({num_rows} points)')\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    \n",
    "    plt.show()\n",
    "    print(f\"Plot displayed for Vehicle {vehicle_id} - Trip {trip_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save DF to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mDataFrame stored to ./visualize_dangers.csv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "visualize_dangers_path = \"./visualize_dangers.csv\"\n",
    "merged_dfs.to_csv(visualize_dangers_path, index=False)\n",
    "print(Fore.GREEN + f\"DataFrame stored to {visualize_dangers_path}\" + Style.RESET_ALL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGIS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
